---
title: 'Project-develop-notes'
date: 2022-03-14
permalink: /posts/2022/03/Project-develop-notes/
tags:
  - cool posts
  - category1
  - category2
---

Some work experience on project developing.

# 技术选型

## 数据库选型

* 存储功能是否能够实现
* 存储量级是否满足需求--查资料获得
* 查询效率是否满足要求

## 软件设计相关原则

* Don't repeat yourself：代码复用性提高，相同功能抽象成新方法。
* Keep it simple：代码设计越简单越好，不必过度复杂。
* You Ain't Gonna need it：只考虑、设计、实现目前需要的功能，更多功能后续再添加。
* Program to an interface，not an implementation：注重业务接口，因为接口对于上下游是抽象稳定的。
* High cohension & low coupling 高内聚低耦合：不同服务的配置文件需要分离。
* Soc separation of concerns：开发过程中，通过各种手段将问题分离成小问题，容易解决。
* Acyclic dependency principles: 依赖结构中，不允许出现循环。
* Solid 原则：
  * Single Responsibility Principle：**一个类只做好一件事**
  * Open/Close Principle: **模块是可扩展（新需求）而不可修改的**
  * Interface Segregation Principle：**接口隔离原则-多个专门接口比一个总接口要好**
  * LSP 里氏替代原则：子类可以替换基类出现的地方，且能正常工作（子类需要实现基类方法再拓展）
  * Common Reuse Principle：一个包的所有类被一起重用，重用一个就重用全部。

# 基本点

* 代码复用：开发具体功能的时候使用class更方便模块独立测试和复用，class中一个函数就是一个功能

* **安全问题**：引用来源框架和第三方库：需要关注安全漏洞问题---eg:log4j暴雷

* [日志](https://blog.codinghorror.com/the-problem-with-logging/)

  | Info                                               | Debug            | Error               | Fatal             |
  | -------------------------------------------------- | ---------------- | ------------------- | ----------------- |
  | 1、方法开始和结尾的地方；2、代码、循环和分支的地方 | 传参和结果的地方 | exception、脏数据等 | 未处理的exception |

* 字符编码
  * ASCII码：8字节
  * OEM字符集
  * MBCS和中文字符集（GB2312）

* 异常处理：**任何稳定的程序都会有大量的代码在处理错误**
  * 开发过程中最需要考虑的地方，**不论是数据输入输出还是操作过程当中可能出现的异常都需要报出**，是否再进行后续处理需要根据业务逻辑决定
  * 传统错误检查：通过错误码来判断，注意错误码和返回值不能混淆
  * try、catch、finally： **try当中的东西越少越好，只保留可能出异常的部分**，因为[可能影响性能](https://blog.csdn.net/huangxiongbiao/article/details/49535803)

*  错误处理实践经验
  * 同类错误的定义可扩展+同类错误处理方式相同。
  * 定义错误严重度：例如：Fatal （重大错误）> Error （资源或需求得不到满足）> Warning （不一定是个错误但还是需要引起注意）>Info（信息）> Debug （调试程序）。
  * 尽可能在错误发生的地方处理错误：**简化调用。**
  * **统一错误分类字典**:不论是错误码or异常捕捉。
  * **尽可能在错误发生的地方处理错误：**简化调用。
  *  **错误日志使用错误码：**方便自动化监控，根据错误码定位对应的错误内容。
  * **同一个地方的不停报错，不要都打到日志中：**防止文件过大淹没其他信息。
  * **不要在循环体中做try-catch** **处理：** 放到循环之外。
  * **不要将大量代码放到try-catch****中
  * 为每种错误定义清楚的文档和示例
  *  **需要将错误返回到更高层级处理，那么尽可能返回原始错误。**
  *  **处理错误的同时释放已分配资源。**

# 关于测试

## 断点调试

* 不论java还是python的idea，都可以用debug模式进行断点调试

* 在代码前打上断点后，用**debug模式进入调试，方便看到每一个参数的具体值**
* 具体快捷键看设置

## 开发&测试&生产环境的差异

**测试和生产环境尽量一致，开发环境可以单独，但尽量一致**

具体遇到的问题记录如下：

* windows 2 linux
  * python代码放到Linux环境后，主函数意外的脚本定义的全局变量初始化时，可能出现无法调用的情况.[解决方式：尝试将该变量初始化定义到函数内部。]
  * windows selector 当中的eventloop 在linux当中相似，但最大取值不同。

## 性能测试

* 耗时：打印运行前后时间差（python：time.time();java: System.currentTimeMillis()）

* 压测：不是在常规条件下运行或测试，而是在资源匮乏的条件下进行测试，通常压测资源包括：内存，CPU, 磁盘空间和带宽.

## 测试类

**每一个功能（不论是接口还是具体功能）开发都需要一个独立的单元测试类（写在/Test****目录当中）**

Ps：测试完成后再合并，方便后续错误排查和定位。

## 单元测试

* **Python** **单元测试框架—uniittest**

​      Import unittest 函数库，对每个软件小功能进行测试，确保被覆盖的功能点正常。

# 故障处理

## 恢复

**故障发生时：首先快速恢复故障（前提：快速定位故障源）**

* Amazon 处理方式：每个开发团队至少有1位oncall 工程师，轮换制。一旦发生较大故障，且找不到替代方案，那么这个故障就会提交到一个工单系统里，所有相关团队的oncall 工程师都会被叫到线上处理问题。【work flow：线上签到，检查自己的服务，没有问题就standby；若问题没有被及时解决，就会自动升级到高层，直到svp级别---按照职责分工而不是技能分工。】
* 常用故障恢复方式：
  * 重启&限流：解决可用性而非功能问题。
  * 回滚：解决新代码bug
  * 降级：若代码无法回滚，则采用降级（停服公告，防止事态扩大）
  * 紧急更新：常用手段，自动化统一更新多个系统。

## 复盘

* 整个处理过程：详细记录故障发生到解决的所有细节过程。
* 原因分析：说明故障原因和分析报告。
* 后续整改：对出现的原因和情况提出对应的整改计划。

## 故障前的准备

* 以功能为索引的服务和资源全视图：根据功能整理一个需要用到的资源配置表&出现问题后的故障定位处理和恢复方式，方便故障定位及修复。
* 故障演练：因为故障并不经常发生，但需要演练处理能力。
* 设定故障等级&对应的处理方式：为了确定该故障需要牵扯多大规模的人进来处理。Amazon4级分类：1级-全站不可用；2级-某功能不可用，且无替代方案；3级-某功能不可用，但有替代方案；4级-非功能性故障。
* 灰度发布：减少线上故障影响的范围的发布方式。【金丝雀发布：让一部分用户继续使用产品A，另一部分开始使用B，若B无故障，则逐渐将A替换为B; 若有问题，则在替换过程中逐渐解决问题】

# 大数据相关

## 数据处理

* 真实性核查、数据可读性、数据处理难度、数据寿命确认（是否定期更新）
* 数据清洗：数据处理为格式一致、删除不合格脏数据，方便发布时直接发布清洗过的数据，能够直接导入使用。
* 处理过程中，记录每一步的数据操作过程，方便回溯。
* 其他：数据格式化、删除离群\重复\不良值等、统一数据文件名称，方便后续处理。

## MapReduce

* 一种编程模型，用于大规模数据集（>1TB）的并行计算，便于在**不会分布式并行编程的情况下，将代码部署到分布式系统当中。**
* 主要思想：Map-映射、reduce-规约。---- **将一堆杂乱无章的数据按照某种特征归纳，然后处理得到最后的结果**
* Google 最初设计是为了解决搜索引擎中大规模数据并行化处理的问题。（Map阶段处理的可以是完全不相关的原始数据、Reduce 阶段根据map和shuffle之后的数据进行键值对处理操作). Java类似于MapReduce的Hadoop并行计算框架。

### 主要构成

mapReduce的三个阶段：**map->shuffle->reduce**

* Map: 处理（可以完全不相关的）原始数据并转化为键值对【提取数据特征】

* Shuffle：为了Reduce能够并行处理Map之后的结果，需要**对map输出的键值进行一定的排序和分割**【提取到的特征预处理】

* Reduce:将相同的key-value进行处理（合并）等操作后输出新的键值对。

  <img src='/images/img/mapreduce.png'>

  说明：

* 每次查询至少需要遍历整个or绝大部分数据，在合理范围内对数据进行动态处理。
* 适合**”没有用户等待的离线使用场景“**，因为无法在短时间内得到查询结果。
* Streaming 作为接口使得可以利用各种语言实现MapReduce

### 主要技术特征

* 集群构建过程可以完全选用价格便宜，易于扩展的低端商用服务器。
* 

# 其他

* git: 具体操作详见git_notes文档，**提交的版本最好是:测试和迭代稳定的版本、便于代码回溯**

## 僵尸进程

* 现象：PS 观察到<defunct 进程>[参考](https://blog.csdn.net/Alexbyy/article/details/112989111)

* 产生原因：**子进程比父进程先结束，但父进程又没有回收子进程并释放子进程占用的资源，此时子进程将会成为一个僵尸进程**

  PS: 若父进程先退出，子进程被init 接管，退出后，init会回收其占用的相关资源。

  * 当一个进程创建了子进程的时候，他们的运行是异步的（父进程无法知道子进程结束时间)。当**父进程很繁忙来不及wait子进程时**，子进程结束时，父进程会丢失子进程结束的状态信息。
  
    --- linux 提供了机制，确保：父进程想要知道子进程状态时就一定能获得。
  
  * 上述linux机制：**在每个进程退出时，内核释放该进程所有资源，包括打开的文件&占用的内存，但仍保留一些信息，留下一个僵尸进程Zombie的数据结构（包含pid，退出状态，运行时间等），这些信息直到调用wait/waitpid时才会释放**
  
* **<u>僵尸进程是每个子进程的必经状态</u>**：任何一个子进程（init除外）在exit（）之后，并非马上就消失掉，而是留下一个称为僵尸进程（Zombie）的数据结构，等待父进程处理。这是每个子进程在结束时都要经过的阶段。

  * 如果子进程exit（）后，父进程来不处理，这时ps命令看到子进程的状态是“Z”。
  * 若父进程能及时处理，ps来不及看到子进程的僵尸状态，但不等于子进程不经过僵尸状态。

* 可能的危害：少量僵尸进程不会带来很大危害，但 1）pid 长期不释放，占用过多，导致系统不能创建新进程。2）僵尸进程过多，init接管速度变慢，消耗系统资源。
* 解决方案：**为了方便进程管理，大量的进程可以直接使用进程池方便管理操作。**

## 内存占用排查

* 现象：使用docker封装python 代码后，跑一段时间会发生内存占满的情况  &  Docker stats: mem%/limit 百分比接近1 &  Free –h 查看内存状态后几乎占满。
* 解决方案：[docker 容器结束后自动释放资源](https://blog.csdn.net/sinat_41667855/article/details/117217678),可以按照业务逻辑，一定时间后重启docker任务

## 缓存排查

* 现象：本地断网的过程中跑docker 服务发现，free –h 观察数据后发现buff/cache 会出现占用增大的情况。

* 解决方案：

  * linux 清理缓存的命令定期执行，能清理出大部分缓存。

  * 清理pagecache命令：**echo 1 > /proc/sys/vm/drop_caches**

    ps：pagecache全部是对文件系统的频繁读写操作进行缓存。




------

