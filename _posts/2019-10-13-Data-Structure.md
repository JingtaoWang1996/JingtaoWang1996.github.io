---
title: 'Data-Structure-notes'
date: 2019-10-13
permalink: /posts/2019/10/Data-Structure-notes/
tags:
  - cool posts
  - category1
  - category2
---

Some data structure related notes.



# Basic take-ways

* 数据结构为算法服务 & 算法要作用在特定的数据结构上。
* 最重要概念-复杂度分析。

# 复杂度分析

不用具体的测试数据来测试，粗略估计执行效率的方法。

* 越高阶复杂度的算法，执行效率越低，
* 从低到高阶：O(1)、O(logn)、O(n)、O(nlogn)、O(n^2)

时间复杂度

**大O复杂度表示法：T(n)=O(f(n))** --- 代码执行时间与代码中表达式成正比

* **大O**-时间复杂度:不具体表示代码真正执行时间，而是**代码执行时间随数据规模增长的变化趋势**，所以又叫**”渐进时间复杂度“**。
* **<u>n表示数据规模的大小</u>**：为了表示增长趋势，当n极大时，**常量、系数、低阶**三部分均忽略不计。

空间复杂度

* 全称：**渐进空间复杂度（asymptotic space complexity**）。
* 表示**<u>算法的存储空间与数据规模之间的增长关系。</u>**

## 时间复杂度分析

常见分析方法：

* **只关注循环执行次数最多的一段代码**：这段代码执行次数的n的量级，就是整段代码的复杂度。
  * 只包含一个执行n次的循环，则：O(n)
  * 一个执行n次的循环当中还包含一个执行n次的循环，则：O(n^2)
* **加法法则：总复杂度等于量级最大的那段代码的复杂度**
  * O(n)  和 O(n^2) 的总复杂度为O(n^2)
* **乘法法则：嵌套代码的复杂度等于嵌套内外代码复杂度乘积**
  * 循环内外复杂度乘积

几种常见时间复杂度分析

| 最高系数         | 复杂度   |
| ---------------- | -------- |
| 常量阶[非多项式] | O(1)     |
| 对数阶           | O(logn)  |
| 线性阶           | O(n）    |
| 线性对数阶       | O(nlogn) |
| 指数阶           | O(2^n)   |
| 阶乘阶[非多项式] | O(n!)    |
| 次方阶           | O(n^k)   |

* 常量阶：代码执行时间不随数据规模增大而增大，时间复杂度为O(1)【无：循环、递归】

* 对数阶、线性对数阶：

  * 例子：i从1开始，每循环一次就*2，直到大于n---O(x=log2n)【2的n次方后大于】

    ```python
    i = 1
    while i<n:
       i = i*2
    ```

    PS: 不管以多少为底数，类似上述例子的时间复杂度都为：**O(logn)**

* O(m+n)  &  O(m*n): 代码复杂度由两个数据规模来决定

  * O(m+n)：代码块中包含两个并列的循环块，且**无法评价两个循环的数据量哪个大的情况下**，两个部分都不能省略，因此时间复杂度为O(m+n)
  * 乘法法则仍然有效。

### 最好、最坏情况时间复杂度

* Best case time complexity：最理想情况下执行这段代码的时间复杂度。
  * eg：在list中遍历查找变量，找到后退出；最好的情况，第一个就是要查找的，时间为O(1)
* Worst case time complexity：最坏情况下执行这段代码的时间复杂度。
  * eg：在list中遍历查找变量，找到后退出；最坏的情况，最后一个才是要查找的，时间为O(n)

### 平均情况时间复杂度

* Average case time complexity：

  * eg: 【在list中遍历查找变量，找到后退出--一共n+1中情况=n个位置+不存在】

    将每种情况下需要遍历的元素个数累加然后除以所有的可能，就得到需要遍历的元素平均值。
    $$
    ((1+n)*n/2+n)÷(n+1)=n(n+3)/2(n+1)
    $$
    去掉常数、系数、低阶后：O(n)；这种计算方式存在的问题是：n+1种情况出现的概率不同。

* 一般情况下考虑最好最坏的极端情况即可，计算平均时间复杂度需要考虑不同情况的出现概率。

### 均摊时间复杂度

* 使用情况更加特殊：操作之间存在前后连贯的时序关系时，可以将这一组操作放在一起，看是否能将较高时间复杂度的操作耗时平摊到其他操作上。

* 一种特殊的平均情况时间复杂度。


## 空间复杂度分析

* 常见的空间复杂度： O(1)、O(n)、O(n2 )，像 O(logn)、O(nlogn) 对数阶复杂度平时都用不到。
* 空间复杂度计算：申请一个list，根据代码（eg：循环中不断向list存入数据）数据量扩大可能导致的不同量级的空间复杂度。

# 数组Array

* 定义：**线性表**数据结构，用一组**连续的内存空间**，来存储一组具有**相同类型的数据**。

  * 线性表：数据排列成像一条线一样的结构，每个线性表上最多只有前后两个方向。【数组、链表、队列、栈也是线性表结构】
  * 非线性表：数组不是简单的前后关系【二叉树、堆、图等】
  * **连续的内存空间&相同类型的数据**：有这两个条件能确保随机访问。但同时导致若想要在数组中删除、插入一个数据，需要做大量数据迁移【为保证数据连续性】

* 数组实现下标随机访问数组元素--连续内存空间&相同类型数据为前提

  * 每个数组元素对应的内存地址计算公式

    ​           a[i]_address = base_address + i * data_type_size

    PS: 已知基地址数组开头元素的内存地址，要求第几个元素，数据类型对应的data_type_size

* 数组和链表的区别

  * 数组适合查找，时间复杂度为O(logn)
  * 数组支持随机访问，根据下标随机访问的时间复杂度为O(1)

## 低效的插入和删除 & 改进方法

插入（长度为n的数组，将元素插入到第k个位置）

* 有序的情况下：k-n的所有元素往后移动一位，时间复杂度：末尾O(1),开头O(n),平均O(n)
* 无序：为了避免数据大规模搬动，直接将原来第k位的元素放到最后，然后插入新的，O(1)。

删除（长度为n的数组，删除第k个位置元素）

* k-n的所有元素往前移动一位，时间复杂度：末尾O(1),开头O(n),平均O(n)
* **将多次删除操作集中到一起执行，可以减少数据搬动：记录所有需要执行的删除操作后，最终统一搬动数据。------JVM标记清除垃圾回收的核心思想**

## 数组访问越界的问题

* 下述述代码中，数组大小为3，但循环中访问了a[3], 在C语言中，只要不是受限制内存，所有内存都可自由访问，根据基地址计算公式，访问到另一个不属于数组的内存地址。这个地址正好是i的内存变量地址，因此a[3]=0 相当于i=0，导致代码无限循环

```c
int main(int argc, char* argv[]){
    int i = 0;
    int arr[3] = {0}; // 数组大小为3,a[0]-a[2]
    for(; i<=3; i++){
        arr[i] = 0;
        printf("hello world\n");
    }
    return 0;
}
```

PS: C中，数组越界没有明确规定编译器如何处理，可能导致逻辑错误&代码攻击等等。

PPS: Java 中本身就会做数据越界检查：**java.lang.ArrayIndexOutOfBoundsException**

## 容器能否完全替代数组

针对数组类型，很多语言都提供了容器类，以Java为例：ArrayList

ArrayList VS 数组

* ArrayList

  * 封装数组操作细节 
  * **支持动态扩容**【每次空间不够，都会自动扩容为1.5倍】。

  * 但无法定义存储基本类型，eg：int->Integer; long->Long【特别关注性能的情况，可以考虑数组】

* 数组--部分语言中数组需要预先指定大小。

  PS: **扩容涉及的内存申请&数据搬迁较多，最好在创建的之初就能够大致估计一个范围。**

* 为什么数组要从0开始编号而不是从1开始？

​      从0开始编号，能够直接明确第k个元素的地址就是：首地址+k*每个元素所占字节，避免从1开始多一个k-1的运算。【PS: C语言从0开始，之后java等仿照c也从0开始】

# 链表Linked list

通过地址指针将**零散的内存块**串联使用，申请的内存地址不必非要连续。

* 单链表：链表中每个节点包含两部分：该节点的数据data+下一个节点的内存地址next【链表尾节点的next=null空地址】
  * 插入、删除：O(1)【只需要修改前后节点next的值】--插入删除较多，优选链表
  * 随机访问：O(n)【必须按照地址顺序从头开始遍历】--随机访问较多，优选数组
* 循环链表：单链表尾节点next指向头结点
  * 方便从链表尾到链表头的访问过程：特别适合问题数据中具有环形结构特点的情况。
* 双向链表：链表中每个节点包含3部分：上一个节点的内存地址pre+该节点的数据data+下一个节点的内存地址next
  * 需要的存储空间增大，但支持双向遍历，一定情况下操作比单链表更加高效。
  * 删除操作时，已知上下节点的地址，无需在遍历过程保存上一个节点地址，简化遍历过程。
* **空间换时间**：当内存空间充足时，若追究代码执行速度，可选择空间复杂度高，但时间复杂度低的算法or数据结构，反之依然（时间换空间）。

## LRU缓存淘汰算法

Q:缓存大小有限的情况下，当缓存数据被用满的时候，哪些数据应该先被清理，哪些数据应该被保留？

A：根据淘汰策略来定：先进先出、最少使用策略、最近最少使用策略（Least Recently Used）

具体操作【以链表为例，也可以通过其他数据结构实现，主要是要一个**访问时间的先后顺序**】

* 维护一个**有序单链表，越靠近链表尾部的节点是越早之前访问的**，当新数据被访问时，从头遍历一次链表。
* 若在链表中找到对应数据，则将原数据从链表中删除，重新放入链表头【访问时间更新】
* 若没有在链表中：1）缓存未满，则新数据放入链表头 2）缓存已满：删除尾节点，数据放入头结点【缓存淘汰】

## 链表的操作

可以画图理好顺序后再具体实现

* 注意**指针的操作顺序**，防止链表丢失or内存泄漏
  * 删除链表节点时，需要手动释放内存空间，防止内存泄露。
* 链表的第一个和最后一个节点在具体进行插入和删除操作的时候，需要对特殊情况进行考虑（空链表的头结点，删除尾节点）
* **头节点**：不存储数据。
* 边界条件检查：**链表为空/只含一个节点/含两个节点/头尾节点处理逻辑/**

## 常见使用-快慢指针！！

* **单链表翻转**：
* 3个指针每次按照顺序修改原链表指针指向
  * 头插法：创建一个新链表，每次从要翻转的链表中取头结点插入到新链表的头结点位置。
  
* **链表中环检测**：快慢指针【快每次2步，慢每次一步-有环（快一定追上慢）；无环（快先到null）】

* 两个有序链表合并：按照顺序选择其中一个链表作为头结点，每次比较两个链表值后移动指针。

* **删除链表倒数第n个节点**：快慢指针【快指针先走n步，然后快慢一起每次一步直到快指针到结尾时删除慢指针对应的链表节点。】

* **求链表的中间节点**：快慢指针【快每次2步，慢每次一步-奇数：快到尾的时候，慢到中间；偶数：快到尾的时候，慢到中间&慢和慢的下一个都是中间】

# 栈 stack

* 浏览器页面前进后退场景【用两个栈来实现】：依次访问页面 a-b-c 之后【X栈存入abc】，点击浏览器的后退按钮，就可以查看之前浏览过的b 和 a。当你后退到 a【Y栈存bc】，点击前进，就可以重新查看 b 和 c。如果后退到 b 后，点击了新页面 d【清空Y栈，X栈留下abd】，那就无法再通过前进、后退功能查看c 了。

* 场景数据抽象特征：**后进先出，只允许在一端插入和删除数据**

* 栈未被数组&链表替代的原因：数组or链表暴露过多操作接口，操作灵活性高，但不可控性增大。

* 主要操作：出栈**pop()**（删除）&入栈**push()**（新增）

* 两种常见的栈：

  * **顺序栈**：数组实现的栈-数组尾部进行新增和删除操作（计算数组长度确认是否能够入\出栈)
  * **链式栈**：链表实现的栈-入栈（头插）&出栈（头节点next指向下一个orNull）
* **<u>入栈 & 出栈：时间复杂度---O(1)  & 空间复杂度---O(1)</u>**【额外使用的内存空间or时间步骤】
  * 动态扩容栈：通过数组动态扩容【链表实质可以一直增加，不存在扩容问题】

## 函数调用中

每进入一个函数，就会将临时变量作为一个栈帧入栈，当被调用函数执行完毕之后，将这个函数对应的栈帧出栈。

## 表达式求值

* 创建两个栈：一个存数，另一个存运算符

* **从左向右遍历表达式，遇到数字，就压入操作数栈；遇到运算符就与操作运算符栈顶元素比较优先级：1）若比栈顶元素优先级高，则将当前元素压入栈；2）若优先级小于等于当前栈顶元素，则取运算符栈顶元素&操作数栈顶两个元素，计算后放入操作数，继续比较。最后在相同级别的运算符当中，两个元素一个符号出栈运算。**
* eg：3+5*8-6【按照上述思路手写一遍即可】

## 括号匹配

假设表达式中只包含三种括号，圆括号 ()、方括号 [] 和花括号{}，并且它们可以任意嵌套

* 表达式从左向右依次扫描：左括号则入栈，右括号则和栈顶取出一个左括号看是否匹配（匹配则继续扫描，直到全部表达式扫描完后判断栈是否为空）

# 队列Queue

* 操作受限的数据表结构，需要两个指针，一个指向队头head，一个指向队尾tail。
* 场景数据抽象特征：**先进先出**。
* 包含的两个操作：在队列两头分别操作。
  * **入队 enqueue()**：**队尾加元素**。
  * **出队 dequeue()**：**队头取元素**。
* **顺序/链式队列**:用数组/链表实现的队列。
* 当tail 到队尾时，再增加元素，可以将 head 到 tail 之间的数据，整体搬移到数组中 0 到 tail-head 的位置。出队操作的时间复杂度仍然是 O(1)，但入队操作的时间复杂度是 O(n)

使用场景：线程池没有空闲线程时，新的任务请求线程资源时，线程池该如何处理？

* 非阻塞的处理方式，直接拒绝任务请求。
* 阻塞的处理方式，通过队列将请求排队，等到有空闲线程时，取出排队的请求继续处理。

## 循环队列

用数组来实现队列的时候，在 tail==n 时，会有数据搬移操作，这样入队操作性能就会受到影响，使用循环队列（首尾相连的队列）能够避免数据搬移。【tail =n，再入队一个元素后tail = 1】

* **队空条件判定：head=tail**
* **队满条件判定：（tail+1）%n=head**【当队列满时，tail实际没有数据，因此循环队列会浪费一个存储空间】
* 循环队列长度需要对并发量有一定的预测，否则容易丢失请求。

## 阻塞和并发队列

* 阻塞队列：在队列为空的时候，从队头取数据会被阻塞；队列已经满了，那么插入数据的操作就会被阻塞。【consumer-producer model：队头消费者，队尾生产者】
* 并发队列：多线程情况下，会有多个线程同时操作队列，这个时候就会存在线程安全问题。最简单直接的实现方式是直接在入队、出队的地方加锁or采用原子操作的方式。

# 递归 Recursion

## 场景：推荐注册返佣金

* 用户 A 推荐用户 B 来注册，用户 B 又推荐了用户 C 来注册。我们可以说，用户 C 的“最终推荐人”为用户 A，用户 B 的“最终推荐人”也为用户 A，而用户 A 没有“最终推荐人”。
* 基于上述映射关系，给定用户id，如何查找其“最终推荐人”

## 递归的三个条件

* 一个问题可以分解为几个子问题的解
* 分解后的子问题除了数据规模不同，求解思路完全一致
* 存在递归终止条件

**--------------------------------写出递归公式 & 找到终止条件-------------------------------------------------**

## 楼梯问题

假如有 n 个台阶，每次你可以跨 1 个台阶或者 2 个台阶，走这 n 个台阶有多少种走法？

* 递归公式：f(n) = f(n-1)+f(n-2)【到当前位置的走法等于到前1阶和前2阶走法之和】
* f(1) = 1, f(2)=2

## 警惕堆栈溢出

实际编写递归代码时，会遇到很多问题，比如堆栈溢出。堆栈溢出会造成系统性崩溃，后果非常严重。

* 递归代码造成堆栈溢出的原因

  函数调用会使用栈来保存临时变量。每调用一个函数，都会将临时变量封装为栈帧压入内存栈，等函数执行完成返回时，才出栈。系统栈或者虚拟机栈空间一般都不大,如果递归求解的数据规模很大，调用层次很深，一直压入栈，就会有堆栈溢出的风险。

* 如何预防堆栈溢出

  **限制递归调用的最大深度的方式来解决这个问题**。【超过一定深度后，不再递归，直接返回报错。】--- 最大允许递归深度可估计且较小时，可以使用这种方法，否则不实用（最大允许的递归深度跟当前线程剩余的栈空间大小有关，事先无法计算。实时计算，代码过于复杂。

## 警惕重复计算

在递归结构计算当中，可能出现某一个子问题的值在多处都需要用到，可以通过一个数据结构（比如散列表）来保存已经求解过的 f(k)。当递归调用到 f(k) 时，先看下是否已经求解过了。如果是，则直接从散列表中取值返回，不需要重复计算。

PS: dp动态规划也是同样的思路。

# 排序

经典排序：冒泡排序、插入排序、选择排序、归并排序、快速排序、计数排序、基数排序、桶排序。

根据时间复杂度划分：

| 排序算法                                     | 时间复杂度 | 是否基于比较 |
| -------------------------------------------- | ---------- | ------------ |
| 冒泡、插入、选择**（使用优先级：插入>冒泡)** | O（n^2）   | yes          |
| 快排、归并                                   | O（nlogn） | yes          |
| 桶、计数、基数                               | O（n）     | no           |

## 算法分析

原地排序：特指空间复杂度为O(1)的算法【排序额外使用的内存空间位常量级】

**执行效率**

* 最好、最坏、平均情况的时间复杂度

  数据无序程度不同，时间复杂度不同。

* 时间复杂度的系数、常数、低阶

  实际开发中，数据规模较小时需要考虑上述三个情况。

* 比较次数和交换/移动次数

**稳定性**：若待排序元素中存在值相等的元素，经过排序后相等元素之间的先后顺序不变。

* 考虑稳定性的场景：电商交易系统中的“订单”排序。订单有两个属性【下单时间、订单金额】。10 万条订单数据，按照金额从小到大对数据排序。金额相同的订单，按照下单时间从早到晚有序。
  * method1：先按金额排序，再遍历排序后的数据，对金额相同的小区间再按照下单时间排序。
  * **method2【稳定排序】：先按时间排序。之后，按金额重新排序。两遍排序之后，得到的数据就是按照金额从小到大排序，金额相同的订单按照下单时间从早到晚排序的[稳定排序确保排序前后顺序不变]。**

## 如何选择合适的排序算法

* 小规模数据：可以选择O(n^2)的算法
* 大规模数据：O(nlogn)

### 快排优化

* privot 区分点选择要合理，尽可能使两侧的数据总量相差不大。时间复杂度可以降为O(n)
* 限制递归深度，防止栈溢出。

## 冒泡 Bubble sort

* **每次只操作相邻的两个数据【相邻两个元素进行比较，看是否满足大小要求，若不满足就互换这两个元素】**
* 一次冒泡会让至少一个元素移动到它应该在的位置，重复 n 次，就完成了 n 个数据的排序工作。

<img src='/images/img/一次冒泡.jpg'>

根据上图，经过1次冒泡之后，6已经到正确为止，因此，长度为6的数组只需6次冒泡即可完成排序。

<img src='/images/img/6次冒泡完成后.jpg'>

* **冒泡优化：**每次记录是否有数据交换，若某次没有数据交换，表示数据已经全排列，结束冒泡。

* **空间复杂度：O(1),只涉及相邻数据的交换操作，需要常量级的额外空间，原地排序算法。**
* 冒泡是稳定排序算法，因为相邻两个元素相等不做交换，保证了顺序。
* **时间复杂度：最好情况：O(n) 顺序已排好,一次冒泡即可；最坏情况：O(n^2) 完全倒序排列，需要n次冒泡操作；平均：O（n^2）次操作**。
  * **有序度**是数组中具有有序关系的元素对的个数。【当一个序列完全有序时成为满有序度】
  * 逆序度 = 满有序度-有序度

## 插入排序 Insertion Sort

* 将数组分为两个区间，**已排序和未排序区间**。初始已排序区间只有一个元素【数组第一个元素】
* <u>插入算法的核心思想：**取未排序区间中的元素，在已排序区间中找到合适的插入位置插入，并保证已排序区间数据一直有序**。重复这个过程，直到未排序区间中元素为空，算法结束。</u>

* 包含两种操作：比较（找到插入位置）、移动（插入位置元素后移一位，空出当前位置）
* 对于给定的初始序列，移动次数=逆序度
* **空间复杂度：O(1),不需要外部空间辅助，原地排序算法。**
* 插入是稳定排序算法，因为可以将后出现的元素插入相等元素的后面，保证了顺序。
* **时间复杂度：最好情况：O(n) 顺序已排好,逐个插入即可；最坏情况：O(n^2) 完全倒序排列，需要n次插入；平均：O（n^2）次操作**。

## 选择排序 Selection Sort

* 类似插入排序，区分**已排序和未排序区间**，每次从未排序区间找最小元素放入已排序的区间末尾。

  <img src='/images/img/选择排序.jpg'>

* **空间复杂度：O(1)，是一种原地排序算法**

* **时间复杂度：最好情况：O(n) 顺序已排好；最坏情况：O(n^2) 完全倒序排列，需要n次插入；平均：O（n^2）次操作**。

* 选择排序：不稳定排序算法，根据上图，每次找最小值，找法不同，前后顺序也不同。

## 归并排序 Merge Sort-O(nlogn)

* 如果要排序一个数组，先把数组从中间分成前后两部分，然后对前后两部分分别排序，再将排好序的两部分合并在一起，这样整个数组就都有序了。【适合大规模数据排序】

<img src='/images/img/归并排序.jpg'>

参见上图，将数组不停分为前后两部分的过程中逐渐排序，最后一层就是合并两个有序数组。

<img src='/images/img/归并排序合并示例.jpg'>

* 根据上图可以看出，归并在merge过程中优先选取前方数据即为稳定排序。
* **时间复杂度【递归代码】：O(nlogn)--任何情况，可根据递归公式进行推导**
* **空间间复杂度：O(n)--n个单位的临时空间用于进行归并**

## 快速排序Quick Sort-O(nlogn)

* 基本思想：排序数组中下标从 p 到 r 之间的一组数据
  * 选择 p 到 r 之间的任意一个数据作为 pivot（分区点）。
  * **遍历** p 到 r 之间的数据，小于 pivot 的放左边，大于 pivot 的放右边，pivot 放中间。【遍历之后数据前后顺序不变，**稳定排序**】
  * 之后，数组 p 到 r 之间的数据就被分成了三个部分，前面 p 到 q-1 之间都是小于 pivot 的，中间是 pivot，后面的 q+1 到 r 之间是大于 pivot 的。
  * 在左右两个区间重复进行第二步，直到完成排序。【适合大规模数据排序】

<img src='/images/img/快排.jpg'>

快排示例如上图所示

* 涉及交换操作，分区之后相同值的先后顺序会改变，因此**快排不是一个稳定算法。**

* **<u>时间复杂度：O(nlogn)</u>--每次分区都基本在中间的情况下，极端情况每次都选在一边：时间复杂度O(n^2)。**
* **空间间复杂度：O(1)--可以考虑原地排序**

## 桶排序Bucket Sort

* <u>**核心思想：将要排序的数据分到几个有序的桶里，每个桶中的数据再单独进行排序，桶内序完之后，再把每个桶里的数据按照顺序依次取出，组成有序的序列。**</u>

```
原序列：22,5,11,41,45,26,29,10,7,8,30,27，42,43，40
桶1 0-9:5,7,8
桶2 10-19:10,11
桶3 20-29:22，26,27,29
桶4 30-39：30
桶5 40-49:40,41,42,43,45
每个桶中单独排完序之后再按顺序取出。
```

* **时间复杂度：O(n)，不涉及元素比较**

  * n 个待排序数据，均匀划分到 m 个桶内，每个桶里就有 k=n/m 个元素。

  * 每个桶内快排，时间复杂度为 O(k * logk)。m 个桶排序的时间复杂度就是 O(m * k * logk)，因为 k=n/m，整个桶排序时间复杂度就是 O(n*log(n/m))。
  * 当桶的个数 m 接近数据个数 n 时，log(n/m) 就是一个非常小的常量，这个时候桶排序的时间复杂度接近 O(n)。

* 桶排序对数据的要求：

  * **要排序数据需很容易划分成 m 个桶且桶与桶之间有天然大小顺序。**这样每个桶内的数据都排序完之后，桶与桶之间的数据不需要再进行排序。
  * **数据在各桶之间的分布比较均匀。**【若数据经桶划分之后，有些桶数据非常多，有些非常少，很不平均，那桶内数据排序的时间复杂度就不是常量级了。在极端情况下，如果数据都被划分到一个桶里，那就退化为 O(nlogn) 的排序算法了。】

* **桶排序适合用在外部排序中**：

  * 外部排序【大量数据存储在外部磁盘中，因内存有限，无法全部加载到内存的情况。】

  示例：10GB 的订单数据，希望按订单金额（假设金额都是正整数）进行排序，但内存有限，无法一次性把 10GB 的数据都加载到内存中。

  * 先扫描一遍文件，看订单金额所处的数据范围。【假设扫描后，订单金额最小是 1 元，最大是 10 万元。将所有订单根据金额平均划分到 100 个桶里-每个桶范围1k。
  * 理想的情况下，若订单在 1 到 10 万之间均匀分布，那订单会被均匀划分到 100 个文件中，每个小文件中存储大约 100MB 的订单数据，我们就可以将这 100 个小文件依次放到内存中，用快排来排序。所有文件都排好序之后，只需要按照文件编号，从小到大依次读取每个小文件中的订单数据，并将其写入到一个文件中，那这个文件中存储的就是按照金额从小到大排序的订单数据了。

  * 实际情况，金额不一定是均匀分布的 ，所以 10GB 订单数据是无法均匀地被划分到 100 个文件中的。可能某个金额区间的数据特别多，划分后对应的文件就会很大，没法一次性读入内存。对于这些大文件，可以继续进行划分，直到能够读入为止。

## 计数排序Counting Sort

* **核心思想：**要排序的 n 个数据所处的**范围并不大时**，比如最大值是 k，我们就可以把数据划分成 k 个桶。每个桶内的数据值都是相同值，省掉了桶内排序的时间【k个桶一定所有可取的单个值都包含在内】。
  * **示例：高考查分（通过成绩快速排序得出名次）** 考生成绩范围：0- 900 ，这个数据的范围很小，所以可以分成 901 个桶，对应分数 0 -900 。根据考生的成绩，将考生划分到这 901 个桶里。桶内的数据都是分数相同的考生，并不需要再排序。只需依次扫描每个桶，将桶内的考生依次输出到一个数组中【每一个数组长度即为计数值】，就实现了 50 万考生的排序。因为只涉及扫描遍历操作，所以时间复杂度是 O(n)。
  * 桶排序之后的数组依次输出到一个数组中，从前到后依次求和【dp】，此时每个数组元素中的值就是小于等于分数k的考生个数。
* **时间复杂度：O(n)，只遍历，不涉及元素比较**
* **桶排序的一种特殊情况**

## 基数排序Radix Sort

* 10w个手机号从小到大排序：从后到前的顺序对每一位排序，最后经过11次排序，所有手机号码都有顺序了。【从后到前排序的意义：保证了排序稳定性】
* 在数据长度不一致的情况下，可以通过加“0”补齐。**每一位的数据范围不能太大，要可以用线性排序算法来排序，否则，基数排序的时间复杂度就无法做到 O(n) 了**。

<img src='/images/img/基数排序.jpg'>

# 二分查找 Binary Search-O(logn)

最省内存的查找方法【Q： 1kw个8字节的整数数据，设计算法快速判断某个整数是否在这1kw个数据中，算法占用内存不超过100MB】

* **<u>使用条件</u>**：

  * **依赖顺序表结构，简单说就是数组.(不能使用链表，需要根据下标随机访问元素)**
  * **有序数据**
  * 有一定数据量，若数据量很小，则一次遍历即可；数据量过大，内存不支持。

* **时间复杂度：O(logn)**

  假设数据大小是 n，每次查找后数据缩小为原来的一半，也就是会除以 2。最坏情况下，直到查找区间被缩小为空，才停止,则被查找区间的变化情况如下：

  ```
  n,n/2,n/4,n/8,...,n/(2^k)
  ```

  可以看出，这是一个等比数列。其中 n/(2^k)=1 时，k 的值就是总共缩小的次数。而每一次缩小操作只涉及两个数据的大小比较，所以，经过了 k 次区间缩小操作，时间复杂度就是 O(k)。通过n/(2^k)=1 ，可以求得 k=log2n，所以时间复杂度就是 O(logn)。

* 用二分查找可以解决的问题，用散列表、二叉树都可以解决。

## 对数时间复杂度O(logn)

* 极其高效的时间复杂度，有的时候甚至比时间复杂度是常量级 O(1) 的算法还要高效
  * 即使n特别大，logn也会很小
  * 常量级的O(1) 可能表示O(1000)>O(logn)

## 递归与非递归实现

* 最简单的情况：有序数组中不含重复元素

  【非递归】

  ```java
  public int bsearch(int[] a, int n, int value) {
    int low = 0; // 开头下标
    int high = n - 1; // 结尾下标
    // 
    while (low <= high) { // 相遇or相交则退出
      int mid = low + (high-low) / 2; // 计算中间值
      if (a[mid] == value) { // 找到
        return mid;
      } else if (a[mid] < value) { // 大于中间值，则更新low
        low = mid + 1;
      } else { // 小于中间值，则更新high
        high = mid - 1;
      }
    }
    return -1; // 没找到
  }
  ```

  【递归】

  ```java
  // 二分查找的递归实现
  public int bsearch(int[] a, int n, int val) {
    return bsearchInternally(a, 0, n - 1, val);
  }
   
  private int bsearchInternally(int[] a, int low, int high, int value) {
    if (low > high) return -1;
   
    int mid =  low + ((high - low) >> 1); // 位运算方式计算中间值
    if (a[mid] == value) {
      return mid;
    } else if (a[mid] < value) {
      return bsearchInternally(a, mid+1, high, value);
    } else {
      return bsearchInternally(a, low, mid-1, value);
    }
  }
  ```

* 查找第一个值等于给定值的元素

  更新：mid>value, high = mid -1;  mid< value low = mid +1；mid=value, 确定是否为第一个（mid=0 or mid -1 ！=value），若不是，则high = mid -1

* 查找最后一个值等于给定值的元素

  更新：mid>value, high = mid -1;  mid< value low = mid +1；mid=value, 确定是否为最后一个（mid=n or mid+1<n &mid +1 ！=value），若不是，则 low = mid +1

* 查找第一个值大于给定值的元素

  更新：mid<=value,low=mid+1;mid>value: (mid =0 or mid-1<=value) 否: high = mid -1

* 查找最后一个值小于于给定值的元素

  更新：mid>=value,high=mid-1;mid<value: (mid =n or mid+1>=value) 否: low = mid +1

# 跳表Skip list

链表改造后用于二分法查找的数据结构

* 动态数据结构：支持快速插入、删除、查找。
* Redis 中 Sorted Set 就是通过跳表实现。

对于单链表：查找 O(n)

**跳表：将链表增加索引层，减少遍历次数**

<img src='/images/img/跳表.jpg'>

如果要查某个结点，比如 16。可以先遍历索引层，当索引层中值为 13 ，下一结点是 17时，要查找的结点 16 肯定就在这两个结点之间。然后我们通过索引层结点的 down 指针，下降到原始链表这一层，继续遍历。这个时候，我们只需要再遍历 2 个结点，就可以找到值等于 16 的这个结点了。这样，原来如果要查找 16，需要遍历 10 个结点，现在只需要遍历 7 个结点。

* **并不是查询效率越高，提升越明显。**

* **查询任意数据的时间复杂度：O(logn)**
* **空间复杂度： O(n)**

高效的动态插入和删除

* 插入、删除操作的时间复杂度也：O(logn)。

# 散列表 Hash Table-O(1)

应用示例1: Word 文档中的单词拼写检查功能实现

* 定义：散列表，又叫<u>hash表</u>。**支持按照下标随机访问数据的特性，其实是数组的一种扩展，由数组演化而来。没有数组，就没有散列表。**
* **通过key以O(1**)来搜索value的值---{0：info，1：info，2：info，...}

## 散列函数

* hash(key):key是元素键值，hash(key)是计算完成的散列值。

* 散列函数计算得到的散列值是一个非负整数。
* 要想找到一个不同key对应hash值不同的散列函数几乎不可能 & 数组存储空间有限也会增大散列冲突的概率。

## 散列冲突

**再好的散列函数也无法避免散列冲突**

常用的解决散列冲突的两类方法：**开放寻址Open address    链表法 chaining**

### 开放寻址法

* 核心思想：若出现散列冲突，就重新探测一个空闲位置插入，


------

