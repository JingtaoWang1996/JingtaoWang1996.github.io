---
title: 'CS-related-notes'
date: 2019-02-25
permalink: /posts/2019/02/CS-related-notes/
tags:
  - cool posts
  - category1
  - category2
---

Computer Science related notes included.

# 分布式

* **将处理错误的代码当成正常功能代码来处理**
* 对比传统单体架构

|              | 传统单体           | 分布式                   |
| ------------ | ------------------ | ------------------------ |
| 部署         | 不经常&容易部署    | 经常发布&部署复杂        |
| 故障影响范围 | 大                 | 小，分布式隔离性更好     |
| 架构设计     | 难度小             | 难度随服务器数量指数增加 |
| 系统性能     | 响应快，吞吐量小   | 响应慢，吞吐量大         |
| 运维         | 简单               | 复杂                     |
| 扩展性       | 差                 | 好                       |
| 上手难度     | 应用逻辑学习曲线大 | 架构逻辑学习曲线大       |
| 系统管理     | 开发成本           | 服务治理和调度           |

## 架构思想-amazon

* 所有团队的程序模块都要通过 Service Interface 方式将其数据与功能开放出来。
* 团队间程序模块的信息通信，都要通过这些接口，不允许其他通信方式（eg：A直接访问B的数据库等），**只能调用这些Service interface**。
* 任何技术都可使用。
* 所有的service interface 做好设计成为能对外开放的接口。

## 需要注意的问题

* 异构系统标准性：软件、应用、通信协议、数据格式、开发和运维过程是否标准。
* 好的配置管理应该分为3层：底层&操作系统、中间层和中间件、最上层&业务应用。
* 服务依赖性问题：**整个服务依赖链中的稳定性由最差的决定**
  * 非关键服务被关键服务依赖，则非关键业务可被定义为关键业务。
  * 一个服务链上的某个服务挂掉，整个链条可能会一起挂掉。
* 服务治理：定义出服务关键程度，关键业务或服务调用的主要路径。同时确保：应用层上的业务隔离以及数据库上的隔离。
* 多层架构的运维复杂度更大：系统通常分为4层（基础层-硬件设备、平台层-服务中间件层、应用层-业务软件、接入层-接入用户请求的网关等）
  * 任何一层出问题都会导致服务整体出问题
  * **<u>不要相信上游系统不出问题，不能因为对方系统问题，把我们系统影响到</u>**。

## 技术栈

* 提高性能

  | 加缓存   | 负载均衡 | 异步调用     | 数据镜像   | 数据分区   |
  | -------- | -------- | ------------ | ---------- | ---------- |
  | 缓存系统 | 网关系统 | 异步系统     | 数据镜像   | 数据分区   |
  | 缓存分区 | 负载均衡 | 消息队列-kfk | 数据同步   | 分区策略   |
  | 缓存更新 | 服务路由 | 消息持久化   | 读写分离   | 数据访问层 |
  | 缓存命中 | 服务发现 | 异步事务     | 数据一致性 | 数据一致性 |

  * 缓存系统：提高系统访问能力
  * 负载均衡：系统水平拓展，多台机器共同分摊流量请求
  * 异步调用：通过消息队列来对任务做排队处理，减少前端请求峰值，增加系统吞吐量（以实时性作为代价，且需要对消息做持久化。）

* 提高稳定性

| 服务拆分           | 服务冗余             | 限流降级 | 高可用架构 | 高可用运维 |
| ------------------ | -------------------- | -------- | ---------- | ---------- |
| 服务治理，服务调用 | 服务调度、弹性伸缩   | 降级控制 | 多租户系统 | 自动化运维 |
| 隔离故障，模块复用 | 故障迁移，防单点故障 | 服务熔断 | 灾备多活   | 全栈监控   |

## 容错设计

弹力设计（system resilience measurement）：容错能力、可伸缩性、一致性、应对大流量的能力。

* 系统可用性测量（系统在不健康，甚至出错的情况下能够维持运行的能力）：

  ​                                  **Availability = MTTF/(MTTF+MTTR)** 

  * MTTF: mean time to failure，平均故障时长（多长时间出现一次故障）
  * MTTR:mean time to recover，平均恢复时间（故障出现到恢复的时间）

  | 系统可用性      | 宕机时间/年 | 宕机时间/月 | 宕机时间/周 | 宕机时间/天 |
  | --------------- | ----------- | ----------- | ----------- | ----------- |
  | 90%（1个9）     | 36.5d       | 72h         | 16.8h       | 2.4h        |
  | 99%（2个9）     | 3.65d       | 7.2h        | 1.68h       | 14.4m       |
  | 99.9%（3个9）   | 8.76h       | 43.8m       | 10.1m       | 1.44m       |
  | 99.99%（4个9）  | 52.56m      | 4.38m       | 1.01m       | 8.66s       |
  | 99.999%（5个9） | 5.26m       | 25.9s       | 6.05s       | 0.87s       |

* 有计划不可用：日常任务、运维、升级。

* 无计划宕机：系统故障、数据中间故障、自然灾害。

* 故障是正常&常见且不可预测的，容错设计之初就是要考虑 "隔离"来防止故障蔓延。

  * 以服务种类来隔离 & 以用户来隔离（多租户模式： 对于大客户，单独设置专门的服务实例，小客户共享实例，在服务隔离的情况下，确保资源的节约）。

  * 每个服务都有一个自己的数据库（物理隔离），同时准备好对外暴露提供服务。

  * 业务到达每一步可以暂停保存，以确保恢复之后可以从当前位置继续。

* 隔离设计的重点：隔离业务的大小和颗粒度的定义; 系统的复杂度和成本；与设计模式配套使用；运维复杂度；监控系统。

## 关键技术








------

