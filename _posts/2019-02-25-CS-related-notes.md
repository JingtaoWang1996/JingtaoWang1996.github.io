---
title: 'CS-related-notes'
date: 2019-02-25
permalink: /posts/2019/02/CS-related-notes/
tags:
  - cool posts
  - category1
  - category2
---

Computer Science related notes included.

# 分布式

* **将处理错误的代码当成正常功能代码来处理**
* 对比传统单体架构

|              | 传统单体           | 分布式                   |
| ------------ | ------------------ | ------------------------ |
| 部署         | 不经常&容易部署    | 经常发布&部署复杂        |
| 故障影响范围 | 大                 | 小，分布式隔离性更好     |
| 架构设计     | 难度小             | 难度随服务器数量指数增加 |
| 系统性能     | 响应快，吞吐量小   | 响应慢，吞吐量大         |
| 运维         | 简单               | 复杂                     |
| 扩展性       | 差                 | 好                       |
| 上手难度     | 应用逻辑学习曲线大 | 架构逻辑学习曲线大       |
| 系统管理     | 开发成本           | 服务治理和调度           |

## 架构思想-amazon

* 所有团队的程序模块都要通过 Service Interface 方式将其数据与功能开放出来。
* 团队间程序模块的信息通信，都要通过这些接口，不允许其他通信方式（eg：A直接访问B的数据库等），**只能调用这些Service interface**。
* 任何技术都可使用。
* 所有的service interface 做好设计成为能对外开放的接口。

经典资料

* 8条分布式被推翻的基本假设：网络稳定、传输延迟为0、带宽无穷大、网络是安全的、网络拓扑不变、只有一个系统管理员、数据传输成本为0、整个网络同构。

<details>
    <summary>经典图书</summary>
        An introduction to distributed systems【分布式系统提纲】
        Distributed Systems for fun and profit【免费电子书】
        Distributed Systems: Principles and Paradigms
        Scalable Web Architecture and Distributed Systems
        Principles of Distributed Systems【苏黎世联邦理工教材：分布式用到的算法】
        Making reliable distributed systems in the presence of software errors
        Designing Data Intensive Applications
</details>
## 关键理论

### ACID

* A-atomicity 原子性：事务里的所有操作，要么完成，要么不做，只要有一个操作失败，整个事务就失败，此时回滚。
* C-consistency 一致性：数据库处于一致状态，事务的运行不会改变数据库原本的一致性约束。
* I-Isolation 独立性：并发的事情不会相互影响，如果一个事务访问的数据正在被另一个事务修改，只要另一个事务未提交，它访问的数据就没有影响。
* D-Durability 持久性：一旦提交后的事务，它所做的修改将会永久保存在数据库上，即使宕机也不会丢失。
* 一旦下单就减少库存，直到撤销or操作完成之后才释放库存。

### CAP 

对于一个分布式计算系统来说，不可能同时满足以下3点，最多2个

* 一致性Consistency：所有节点同一时间具有相同的数据【要么获得最近写入的数据，要么获得一个错误。】
* 可用性Availability：保证每个请求不管成功或失败都有响应。【每次请求都能获得一个非错误的响应，但不保证返回是最新写入的数据。】
* 分隔容忍Partition tolerance：系统任意信息的丢失或失败不会影响系统运行操作【尽管任意数量的消息被节点间的网络丢失或延迟，系统仍然继续运行。】
* CAP 定理表明，存在网络分区的情况下，一致性和可用性必须二选一。没有发生故障的时候，一致性和可用性可以被同时满足，当网络出现故障情况时，需要维持系统按照正常情况进行运行。【CAP定理的一致性和ACID数据库事务一致性不同】

<img src='/images/img/CAP.png'>

* C+A: 2pc--关注一致性和可用性，需要非常严格的一致协议。Eg: 两段提交等等。不能容忍网络错误或节点错误，一旦出现则整个系统拒绝写入请求。
* C+P:Paxis--一致性和分区容忍性，大多数节点一致即可，少数节点在没有同步到最新版本之前会变成不可用的状态。
* A+P: Gossip--只关心系统可用和分区容忍，因此系统不能达成一致性。需要给出数据冲突，给出数据冲突就需要维护数据版本。

### BASE

允许和容忍系统出现暂时性问题。

* 在用户下单时，大家都可以同时操作，但不真正分配库存，而是通过系统异步批量处理订单，可能出现超卖的情况。

## 需要注意的问题

* 异构系统标准性：软件、应用、通信协议、数据格式、开发和运维过程是否标准。
* 好的配置管理应该分为3层：底层&操作系统、中间层和中间件、最上层&业务应用。
* 服务依赖性问题：**整个服务依赖链中的稳定性由最差的决定**
  * 非关键服务被关键服务依赖，则非关键业务可被定义为关键业务。
  * 一个服务链上的某个服务挂掉，整个链条可能会一起挂掉。
* 服务治理：定义出服务关键程度，关键业务或服务调用的主要路径。同时确保：应用层上的业务隔离以及数据库上的隔离。
* 多层架构的运维复杂度更大：系统通常分为4层（基础层-硬件设备、平台层-服务中间件层、应用层-业务软件、接入层-接入用户请求的网关等）
  * 任何一层出问题都会导致服务整体出问题
  * **<u>不要相信上游系统不出问题，不能因为对方系统问题，把我们系统影响到</u>**。

## 技术栈

* 提高性能

  | 加缓存   | 负载均衡 | 异步调用     | 数据镜像   | 数据分区   |
  | -------- | -------- | ------------ | ---------- | ---------- |
  | 缓存系统 | 网关系统 | 异步系统     | 数据镜像   | 数据分区   |
  | 缓存分区 | 负载均衡 | 消息队列-kfk | 数据同步   | 分区策略   |
  | 缓存更新 | 服务路由 | 消息持久化   | 读写分离   | 数据访问层 |
  | 缓存命中 | 服务发现 | 异步事务     | 数据一致性 | 数据一致性 |

  * 缓存系统：提高系统访问能力
  * 负载均衡：系统水平拓展，多台机器共同分摊流量请求
  * 异步调用：通过消息队列来对任务做排队处理，减少前端请求峰值，增加系统吞吐量（以实时性作为代价，且需要对消息做持久化。）

* 提高稳定性

| 服务拆分           | 服务冗余             | 限流降级 | 高可用架构 | 高可用运维 |
| ------------------ | -------------------- | -------- | ---------- | ---------- |
| 服务治理，服务调用 | 服务调度、弹性伸缩   | 降级控制 | 多租户系统 | 自动化运维 |
| 隔离故障，模块复用 | 故障迁移，防单点故障 | 服务熔断 | 灾备多活   | 全栈监控   |

## 关键技术-全栈监控&服务调度

### 全栈监控

* 需要完成的功能：监控、关联分析、跨系统
* 具体监控：主机和底层资源（cpu、内存等）、中间件状态、应用层（访问量、吞吐量、响应时间等）；同时添加好标准化的日志及日志分析
* 好的监控：故障快速定位、关联聚合指标后展示

### 服务调度

* 定义服务的关键程度（基于对业务的理解）

* 微服务是服务依赖最优解，至少：**服务不能有依赖环**，若有：考虑通过消息中间件等解环。

* 服务状态&生命周期：通过服务中心中间件来管理。

* 整个架构版本管理：VersionSet in Amazon(一堆服务版本集所形成的整个架构的版本控制)

  ​    除了各个项目的版本管理之外，还需要再盖一层版本管理（Build过Linux分发包的话，Linux分发包中各个软件的版本上会再盖一层版本控制，毕竟分发包也有版本依赖，同时解决版本兼容性的问题。）

## 调度

### 流量调度

* 自动调度，无需人工干预，在弹性计算扩容较长事件窗口内或底层资源消耗殆尽的情况下，保持系统平稳运行。
* API gateway：高性能语言、集群技术、业务逻辑简单，服务化(Admin API 来不停机管理变更配置)
* 状态数据的调度：通过第三方服务进行存储。
* 分布式事务一致性问题：各个节点上的数据备份问题，数据冗余解决数据不丢失的问题。（备份、master-slave、master-master、多阶段提交、Paxos）
  * 凡通过业务补偿或在业务应用层上做的分布式都是两阶段提交

### 数据调度

* 分布一致性真正算法：**Paxos**(Lesile Lamport 1990 提出的基于消息传递且具有高度容错性的一致性算法)
* 逻辑钟和向量钟（检测响应的数据冲突）：分布系统钟为了解决消息有序问题而布置的时钟，**由于不同的机器有不同的本地时间，同步这些时间相对困难导致消息乱序。因此，每个系统维护一个本地计数器，每执行一个事件，计数器**+1，跨系统传递时，接收端同步更新自己的计数器。

## 幂等性-去除重复请求

* 幂等设计：一次或多次请求某个资源应具有相同的副作用。
  * 系统解耦隔离后，服务间的调用可能会有三个状态：success, failed,timeout.前两者是明确的状态，第三种不知道是什么状态。【超时可能产生副作用：订单超时是多创建一笔？还是多扣一次钱？】
  * 处理方式：下游系统提供相应查询接口。上游timeout后，下游差一次，查到就不做了，没查到再重复；**幂等性：**查询交给下游系统，上游只管重试，下游保证次和多次重试一致。
* 幂等设计具体实现
  * **全局id**：同一笔交易使用相同的id来保证幂等性。（ID的分配：使用id冲突极小的算法--UUID、snowflake【Twitter提出，long型64位id】）
  * **过滤收到的id是否重复**：幂等性要求下游对收到的id进行存储，用于后续查询。
* http幂等性
  * HTTP get 方法获取资源，无副作用，是幂等的。
  * http head 和 get 本质是一样的，区别在于head 只有头部信息，也是幂等的。[可以用来判断某个资源是否存在—用head 做探活]
  * http options：获取当前URL所支持的方法，幂等。
  * http delete：删除资源，同样幂等。
  * http put：用于创建或更新操作，幂等性。

## 业务补偿

​        现实生活中，大多数情况无法做到强一致的ACID，特别是需要跨多个系统的时候。若仍要保持一致性，需要多个系统统一协调，大概率无法完成。因此，遇到类似情况，当每一部分条件无法满足或者是有变化的时候，需要从业务上进行相应的补偿。补偿机制大致如下：

* 幂等性：一个事务超时or失败，需不断尝试，最终不行or请求变化则需恢复或启动业务更新机制。
* 业务补偿需要：清楚的描述业务需要达到的状态 & 条件不满足需要退回的状态
* 业务补偿可以串并行执行。
* 已经完成的事务进行整体修改，可以考虑构成一个修改的事务。

重点：

*  努力完成业务流程【包含重试、幂等机制；小心维护和监控整个过程的状态（同一个维护系统当中便于检测管理）】
* 如果无法完成，启动补偿机制，回滚业务流程。【业务补偿和业务逻辑强相关，无法通用】

## 相关设计思路

### 容错

弹力设计（system resilience measurement）：容错能力、可伸缩性、一致性、应对大流量的能力。

* 系统可用性测量（系统在不健康，甚至出错的情况下能够维持运行的能力）：

  ​                                  **Availability = MTTF/(MTTF+MTTR)** 

  * MTTF: mean time to failure，平均故障时长（多长时间出现一次故障）
  * MTTR:mean time to recover，平均恢复时间（故障出现到恢复的时间）

  | 系统可用性      | 宕机时间/年 | 宕机时间/月 | 宕机时间/周 | 宕机时间/天 |
  | --------------- | ----------- | ----------- | ----------- | ----------- |
  | 90%（1个9）     | 36.5d       | 72h         | 16.8h       | 2.4h        |
  | 99%（2个9）     | 3.65d       | 7.2h        | 1.68h       | 14.4m       |
  | 99.9%（3个9）   | 8.76h       | 43.8m       | 10.1m       | 1.44m       |
  | 99.99%（4个9）  | 52.56m      | 4.38m       | 1.01m       | 8.66s       |
  | 99.999%（5个9） | 5.26m       | 25.9s       | 6.05s       | 0.87s       |

* 有计划不可用：日常任务、运维、升级。

* 无计划宕机：系统故障、数据中间故障、自然灾害。

* 故障是正常&常见且不可预测的，容错设计之初就是要考虑 "隔离"来防止故障蔓延。

  * 以服务种类来隔离 & 以用户来隔离（多租户模式： 对于大客户，单独设置专门的服务实例，小客户共享实例，在服务隔离的情况下，确保资源的节约）。

  * 每个服务都有一个自己的数据库（物理隔离），同时准备好对外暴露提供服务。

  * 业务到达每一步可以暂停保存，以确保恢复之后可以从当前位置继续。

* 隔离设计的重点：隔离业务的大小和颗粒度的定义; 系统的复杂度和成本；与设计模式配套使用；运维复杂度；监控系统。

### 重试

对于暂时性故障，服务不稳定时增加重试机制（error 重试无意义）

需要注意：

* 设置重试最大次数&重试时间：之后报错。
* 重试之间应该有间隔：避免过快导致网络负担加重。
* Exponential backoff 指数级退避：每重试一次需要的休息时间都会加倍，方便调用方有更多时间来处理请求。

### 熔断

错误太多或者短时间内无法修复时采取熔断，减少错误导致的等待和对系统的影响。

熔断器模式：

* 调用失败计数器，达到阈值，程序断开报错
* 达到一定失败数量时可以阶段性操作，避免偶发性问题。

重点：

* 明确需要熔断的错误类型及对应的策略；
* 日志监控+手动重置
* 测试服务是否可用：定时检查服务是否恢复，用以切换到闭合状态。
* 考虑并发+资源分区+重试错误的请求。

### 限流

* 保护系统不会在过载的情况下出现问题。

* 常见场景：数据库访问的连接池、线程池、Nginx下用于限制瞬时并发连接数的limit_conn模块等

* 策略：限制并发访问速度--一旦到达限制，触发相应的限流行为。常见限流行为如下：
  * 拒绝服务Denial of service DOS：将多出来的请求拒绝掉，统计访问量最多的客户端请求，将该客户端拒绝。【同时避免恶意攻击】
  * 服务降级：关闭或者将后端服务做降级处理，可以让服务有足够的资源来处理更多的请求。[停掉不重要的服务or不再返回全量数据，只返回部分数据]
  * 特权请求：资源不够的时候，只能将资源分配给更高级的用户。
  * 延时处理：在这种情况下，一般会有一个队列来缓冲大量请求，队列满之前队列中缓冲，队列满之后，拒绝掉服务。缓冲队列多用于缓解压力，应对短时峰刺请求。
  * 弹性伸缩：自动化运维方式监控系统服务。

* 限流实现方式：维护一个计数器，来判断是否达到最大请求。也可以通过不同算法实现请求响应的限制。
* 基于时间的动态限流：当无法获取阈值时候，可以考虑通过动态限流的方式来达到目的。[通过记录每次请求响应时间，计算10s内请求时间排序后90%的位置大致是多少来确定当前性能。]
* 设计要点：
  * 设计之初就考虑，防止后期难以加入；限流模块性能必须要足够好，否则延迟过大无意义；限流需要一个手动开关；对于拒绝的请求需要一个返回码
  * 突发流量的应对方案 & 限流节约成本。
  * 防止多租户的场景下，某一租户将资源耗尽。
  *  确保系统在某速度下的响应时间及可用性。【对外界IO无依赖情况下可以做到】

### 降级

* 解决资源不足和访问量过大的问题：当资源和访问出现矛盾时，在有限资源下，对系统进行降级操作，暂时牺牲掉部分东西确保系统平稳运行。

* 一般来说降级需要牺牲掉的东西有：
  * 一致性：从强一致性变为最终一致性。这个世界上大多数系统并不需要强一致性，因此将强一致转为最终一致能够有效降低资源消耗。【eg: 采用异步的方式将单条服务构建成多条一致】   PS：功能降级一般会损害用户体验，因此可以加入“系统当前繁忙，您的订单已收到，我们正努力为您处理订单中，我们会尽快给您发送订单确认通知……还请见谅”等友好提示。
  * 停止次要功能：停止访问不重要的功能，从而释放更多资源。【因为停掉部分功能会影响用户体验，因此恢复后最好给用户一些补偿（eg：积分卡等）】
  * 简化功能：eg:全量数据改为部分数据。【一般API会有两个版本，一个返回全量，一个返回部分/最小可用数据】

* 设计要点：
  * 降级条件：吞吐量、响应时间、失败次数等。满足条件后用自动化脚本进行处理。
  * 功能降级：确定好可以牺牲的功能和必须保证的功能。
  * 降级功能开关可配置：相应的在对外API名称上有区别。

* 降级属于应急情况，所以降级的业务流程可能因为长期不使用而产生bug，需要平时做一些演练。


------

