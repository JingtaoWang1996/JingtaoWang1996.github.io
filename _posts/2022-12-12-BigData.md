---
title: 'BigData'
date: 2022-12-12
permalink: /posts/2022/12/BigData-Intro/
tags:
  - Theoretical Ground
  - System Optimization
---

Some Big Data related notes.

# 背景

## 起源

*  2004年---Google的三篇论文：分布式**文件系统** GFS、大数据分布式**计算框架** MapReduce 、NoSQL **数据库系统** BigTable。
  * 解决的问题：搜索引擎中网页抓取&索引构建产生的**<u>大量存储和计算问题</u>**。
* 2006年---DoungCutting 分离Nutch中的大数据相关功能，产生Hadoop(分布式文件系统HDFS+大数据计算引擎MapReduce)
*  Facebook发布Hive，支持使用sql语法进行大数据计算(sql转成MapReduce计算程序)。
* 2012年---Yarn 资源调度框架开始。
  * 解决的问题：MapReduce既是执行引擎，又是资源调度框架。Yarn出现，将MapReduce优化为单独的执行引擎。
* 2012年---UC 伯克利 AMP 实验室（Algorithms-Machine-People）开发Spark 。
  * 解决的问题：
    * MapReduce进行ML计算性能差，MapReduce每执行一次Map和Reduce都要重启代码。
    * MapReduce 使用磁盘作为存储介质，2012 年时，内存已经突破容量和成本限制，成为数据运行过程中主要的存储介质。

## 大数据计算处理方式

* **批处理计算/大数据离线计算**：MapReduce、Spark 这类计算框架处理的业务场景。通常针对以“天”为单位产生的数据进行一次计算，然后得到需要的结果，计算需要花费的时间大概是几十分钟甚至更长的时间。

  * 批处理计算的数据非在线得到的实时数据，而是历史数据，因此是离线计算。

* **大数据流计算/大数据实时计算**：对实时产生的大量数据进行即时计算。eg：监控摄像头进行人脸识别和嫌犯追踪。

  * 流计算框架：Storm、Flink、Spark Streaming 。

* 典型大数据业务场景下，数据业务最通用的做法：

  * 批处理技术处理历史全量数据，采用流式计算处理实时新增数据。

    PS: 类似Flink 的计算引擎，可同时支持流式计算和批处理计算。

* **NoSQL 系统处理**：大规模海量数据的存储与访问。

* **移动计算代码：** 将代码分发到数据的位置进行计算 instead of 将数据传到代码所在位置。【数据量>> 代码量，移动代码到数据所在位置计算的成本更小。】

  具体实现

  * 大规模数据存储在集群服务器上。【使用HDFS分布式文件存储系统，将文件分成很多block，以块为单位存储在集群的服务器上。】
  * 大数据引擎根据不同服务器计算能力，在每台服务器上启动若干分布式任务进程等待任务分配。
  * 使用大数据计算框架支持的编程模型进行编程。【eg：MapReduce、Spark 的 RDD】 
  * Hadoop 或者 Spark 的启动命令执行这个应用程序的 JAR 包。【执行引擎解析程序要处理的数据，根据输入数据量的大小，将数据分片（Split），每个数据片分配给一个任务进程去处理。
  * 任务执行进程收到分配的任务后，检查自己是否有任务对应的程序包，如果没有就去下载程序包，下载后通过反射的方式加载程序。走到这里，最重要的一步-移动计算就完成了。
  * 加载程序后，任务执行进程根据分配的数据片的文件地址和数据在文件内的偏移量读取数据，并把数据输入给应用程序相应的方法去执行，从而实现在分布式服务器集群中移动计算程序，对大规模数据进行并行处理的计算目标。

* 关于**HDFS**:

  * HDFS也许不是最好的大数据存储技术，但依然最重要的大数据存储技术。
  * HDFS作为最早的大数据存储系统，存储着最宝贵的数据资产。新的框架、算法要想应用就必须支持HDFS。
  * Hadoop 分布式文件系统 HDFS 的设计目标: 管理数大量服务器及磁盘，并将其当做一个单一的存储系统进行管理，对应用程序提供数以 PB 计的存储容量，让应用程序像使用普通文件系统一样存储大规模的文件数据。
    * HDFS在一个大规模分布式服务器集群上，对数据分片后进行并行读写及冗余存储。集群中所有服务器的磁盘都可供 HDFS 使用，所以整个 HDFS 的存储空间可以达到 PB 级容量。
    *  HDFS 的两个关键组件：DataNode & NameNode。
      * **DataNode：文件数据的存储和读写操作。**HDFS 将文件数据分割成若干Block，每个 DataNode 存储一部分数据块，这样文件就分布存储在整个 HDFS 服务器集群中。应用程序客户端可**并行**访问这些数据块，提高访问速度。
      * **NameNode：整个分布式文件系统的MetaData（文件路径、数据块ID、存储位置信息）管理，相当于操作系统中文件分配表FAT**。为保证数据的高可用，会将一个数据块复制为多份（缺省情况为 3 份），并存储在不同的服务器、甚至不同的机架上。

* 关于**MapReduce**：既是一个编程模型，又是一个计算框架。

  * MapReduce使大数据计算通用编程成为可能。只需遵循 MapReduce 编程模型构建业务处理代码，就可以运行在Hadoop 分布式集群上，无需关心分布式计算具体完成方式。
  * 编程模型：只包含 Map & Reduce 两个过程。
    * map输入一对 <Key, Value> ，计算后输出一对 <Key, Value> 
    * 合并相同 Key ，形成 <Key, Value 集合 >
    * <Key, Value 集合 > 输入 reduce，计算输出零个或多个 <Key, Value> 对。
  * 数据和并与连接机制**shuffle**：经过shuffle之后，将不同服务器上的相关的数据合并到一起进行下一步计算操作。

* 关于**Spark**：提高MapReduce大数据计算效率。

  * 对比MapReduce 和 Spark的计算阶段：
    * MapReduce 一个应用一次只运行一个 map 和一个 reduce 。
    * Spark 可根据应用复杂度，分割成更多的计算阶段，这些计算阶段组成一个有向无环图 DAG，Spark 任务调度器可以根据 DAG 的依赖关系执行计算阶段。【避免一次性启动上万个进程占用资源。】
  * spark执行过程支持：Standalone、Yarn、Mesos、Kubernetes 等多种方案。
  * 三个主要特性：RDD编程模型更简单、DAG有向图切分的多阶段计算过程更快速、内存存储中间计算结果更高效。

* 关于**BigTable**：开源实现HBase(nosql)

  * HBase(nosql数据库)简单暴力地认为，数据库只存储数据，业务逻辑应该由应用程序去处理。
    * HBase 非key列的查询非常慢。
  * 可伸缩架构：主要依赖可分裂的HRegion 及可伸缩的分布式文件系统 HDFS 实现。
    * HRegion：HBase 负责数据存储的主要进程，对数据的读写操作都是通过和 HRegion 通信完成。**在 HBase 中，数据以 HRegion 为单位进行管理**，想要访问一个数据，必须先找到 HRegion，然后将数据读写操作提交给 HRegion，由 HRegion 完成存储层面的数据操作。
      * HRegionServer 是物理服务器，每个 HRegionServer 上可启动多个 HRegion 实例。当一个 HRegion 中写入数据太多达到配置阈值时，一个 HRegion 分裂成两个，并将 HRegion 在整个集群中迁移，以使 HRegionServer 负载均衡。
      * 如果集群中有新加入的服务器（新的 HRegionServer)，由于其负载较低，也会把 HRegion 迁移过去并记录到 HMaster，从而实现 HBase 的线性伸缩。
  * 可扩展模型：许多 NoSQL 数据库使用列族（ColumnFamily）解决数据变更带来的挑战。列族最早在 Google 的 BigTable 中使用，是一种面向列族的稀疏矩阵存储格式。
  * 高性能存储：为了提高数据写入速度，HBase 使用**LSM 树**的数据结构进行数据存储。LSM 树的全名是 Log Structed Merge Tree（Log 结构合并树）。数据写入时以 Log 方式连续写入，然后异步合并磁盘上的多个 LSM 树。
    * **LSM 树**：可看做一个N 阶合并树。数据写操作都在内存中进行，完成后都会创建一个新记录。数据在内存中仍然还是一棵排序树，**当数据量超过设定的内存阈值后，会将这棵排序树和磁盘上最新的排序树合并**。合并过程，最新更新数据覆盖旧数据（或记录为不同版本）。
    * LSM 树上进行一次数据更新：不需磁盘访问，在内存即可完成。当数据访问以写操作为主，读操作集中在最近写入的数据上时， LSM 树可极大减少磁盘访问次数，加快访问速度。

# 流式计算处理

**Storm**

* 最早用消息队列实现大数据实时处理，如果处理起来比较复杂，就需要很多个队列，串联实现不同业务逻辑的生产者和消费者。这样每次开发一个新项目就会涉及重新开发一套消息队列，异常麻烦。

* 之后，很自然地想到开发一个流处理计算系统，定义好处理流程和每一个节点的处理逻辑，代码部署到流处理系统后，就能按照预定义的处理流程和处理逻辑执行。【storm的产生，早期的大数据流计算框架】
* 基于storm，开发者无需再关注数据流转、消息处理和消费，只需开发好处理逻辑和数据源逻辑即可。

**Spark Streaming**

* Spark是一个批处理大数据计算引擎，针对大批量**历史数据**进行计算，它将原始数据**分片后**装载到集群中计算，对于数据量不是很大、过程不是很复杂的计算，可以在秒级甚至毫秒级完成处理。
* Spark Streaming 利用Spark 的**分片**和**快速计算**的特性，将实时传输进来的数据**按照时间分段**，合并一段时间传输进来的数据，当作一批数据后再去交给 Spark处理。
  * **极小时间段**的每一段数据量就会极小+spark处理数据本身很快 = 数据被实时处理。 

**Flink**

与Spark Stream 将实时数据流按时间分段相反，Flink按照流处理设计、

* 把文件系统HDFS读入数据当做数据流看待，就变成批处理系统了。【既可以流处理又可以批处理】

# 大数据基准测试

**HiBench**

* 内置若干主要的**大数据计算程序**作为基准测试的负载。

* 支持的大数据框架包括 MapReduce、Spark、Storm 等。

使用简单：

* 配置：配置好要测试的数据量、运行环境、路径信息等基本参数。
* 初始化数据：生成准备要计算的数据。
* 执行测试：运行对应的大数据计算程序。




------

