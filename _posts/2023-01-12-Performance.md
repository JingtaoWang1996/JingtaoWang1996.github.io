---
title: 'Performance-related'
date: 2023-01-12
permalink: /posts/2023/01/Performance-related-notes/
tags:
  - Theoretical Ground
  - System Optimization
---

Some performance related development notes.

# 相关定律

**性能好的几个常见指标**

* 吞吐量Throughput：单位时间处理的请求量。
* 服务延迟Service Latency：客户请求的处理时间。
* 扩展性 Scalability：系统高压情况下能否正常处理请求。
* 资源使用效率Resource Utilization：单位请求处理所需要的资源量（CPU、内存等）

根据具体场景不同，还可能有其他性能指标。

## 帕累托法则

又名 80/20、关键少数、八二法则。很多场景下20%的因素操控80%的局面，**关键因素在少数**。【eg:80%的销售额来自20%的客户。】

| 场景               | 帕累托法则                     | 指导意义                         |
| ------------------ | ------------------------------ | -------------------------------- |
| 代码使用           | 80%用户使用集中在20%的功能模块 | 常用模块进行充分优化             |
| 开发时间分配       | 80%时间在20%最关键代码开发     | 合理规划好开发时间               |
| 代码维护           | **80%代码改动在20%的代码上**   | 最常改动的少部分代码尽量熟悉     |
| 客户流量和时间分布 | 80%流量在总时间段20%内         | 充分考虑访问时间的峰值和空闲时段 |
| 代码优化           | 80%的时间在运行20%的代码       | 发现少数重点代码并做优化         |

## 阿姆达尔定律

* 衡量处理器进行**并行处理**时总体性能的提升度。
* 用多处理器并行加速时，**总体程序受限于串行时间的百分比。**【串行时间无法通过并行优化，需要改进串行代码本身】

* 实际优化中的意义：优先优化加速占用时间最多的模块，可以最大限度提升效果。

## 利特尔法则

稳定系统中，长期的平均客户数N=客户抵达速度X *客户在这个系统中平均处理时间W

* 设计性能测试环境的基准【设计一个完全能够达到效果的基准】
* 验证测试结果的正确性【调整是否有效】

## 排队论Queuing Theory

* 主要输入参数：请求到达速度、请求到达分布、排队规则、请求处理速度、请求处理模型等。
* 主要输出参数：排队长度、等待时间、系统负载、空闲率等性能指标参数。

# 性能数据展示经验

* 目的：报告性能趋势和流量预测结果；描述性能问题根因分析；建议性能升级和代码优化。
* 展示的难点和挑战：几十上百个指标组合构成的性能数据图数据量大、交互关系负载、牵扯模块多
* 具体展示经验：
  * 不同听众，不同层面展示：向上-宏观；同事-细节。
  * 给足上下文：背景情况介绍详细，确保听众能get到问题点。
  * 总结重点：数据展示完之后，一定要简明的总结重点。

# 一组常用性能数字

每次看到一个性能相关的数据，就能立刻直到这个性能有没有问题。

## 存储相关

存储有很多种，常用的是传统硬盘（Hard Drive Disk) 和 固态硬盘（Solid State Drive）

对所有存储来说的三个基本性能指标：

* IO读写延迟
* IO带宽
* IOPS-每秒可读写多少个小的随机IO

| 存储种类  | 随机4KB-IO延迟 | IO带宽  | 随机IOPS |
| --------- | -------------- | ------- | -------- |
| HDD       | 8ms            | 150MB/S | 120      |
| SSD(SATA) | 100μs          | 500MB/S | 30K      |
| SSD(NVMe) | 20μs           | 4GB/S   | 400K     |

## CPU和内存相关

* 每个指令周期数CPI(Cycles per instruction):平均每条指令的平均时钟周期数。
* 每个周期指令数IPC：虽然一个指令执行需要多个周期，但IPC仍然可以大于1，小于1则性能需要优化。
* MIPS:每秒执行的百万指令数：MIPS越高，CPU性能越好。
  * MIPS= 主频*IPC
* CPU缓存：一般CPU都有L1、L2、L3 级缓存，缓存等级数字越大，缓存越慢但同时成本越低。【L1,L2一般在cpu核上，L3各个核共享。】

## 操作系统和应用程序相关

* 指令分支延迟：CPU需要先获得指令，然后才能执行。获取下一条指令需要知道指令地址（若这个地址需要根据现有指令计算才能确定，则构成指令分支）。

  * CPU通常采取提前提取指令来提高性能，若出现指令分支，就可能导致预测错误，需要十几个时钟周期来重新提取指令，延迟在**10ns左右**

* 互斥加锁和解锁

  保证多线程执行后数据同步，加解锁每个操作都需要几十个时钟周期，**10ns以上**。

* 上下文切换

  多进程or线程共享CPU时，就需要经常做上下文切换，时间消耗在**1μs左右**。

# 性能测试

​        确保代码在一定负载流量下运行良好，发现和性能相关的各种问题和性能瓶颈，进而消除可能的错误和性能瓶颈。

* 黑盒：将测试对象当做整体，不关注其内部工作机制。
* 白盒：关注内部工作机制的情况。

## 常见几种测试

| 低流量        | 中等流量      | 大流量   |
| ------------- | ------------- | -------- |
| 冒烟测试      | 负载测试      | 容量测试 |
| 耐力/浸泡测试 | 断点/尖峰测试 | 瓶颈测试 |
| 基准/回归测试 | 可扩展性测试  | 压力测试 |

* 冒烟测试Smoking Test：开发环境中执行的简单测试，确定新代码没有bug，功能基本正常。
* 耐力测试Endurance Testing or 浸泡测试 Soak Testing：非功能性测试，长时间测试具有预期负载量的系统，验证系统功能、性能等是否正常。【多用于暴露某些不易重现的问题：内存、系统故障or其他随机问题】
* 基准测试Benchmark Testing / 性能回归测试 Performance Regression Testing：代码修改前后进行基准测试，比较前后性能结果，以确保新代码对系统or性能不会产生不好的影响。【前提：前后测试环境一致】
* 负载测试Load Testing：验证代码是否可以处理预期的负载流量以及正常和峰值情况下的系统程序行为。
* 断点测试breakpoint testing：随时间推移而增大流量负载同时检测系统的预定故障条件。用于测试能够达到的最大容量，以及对应的处理策略。
* 尖峰测试Spike testing：确定系统在负载突然变化时的系统行为，通过突然增加or减少用户产生的负载来测试。【目标：确认性能在这样的场景下是否会受损，压测的一种】
* 可扩展性测试：Scalability Testing-系统能否在变化的环境中合理扩展【系统环境变化、负载大小变化、请求多样性变化等】
* 容量测试capacity Testing：确定一个单位容量能支持的最大负载。确定每台服务器能够支持的最大容量之后才能进行相应的调整。
* 压测：不断增加负载后观察哪个模块或组件首先因超载而fail，进而进行优化。

## 性能测试的规划和具体执行步骤

* 确定被测试系统 System Under Test
* 确定需要测试的性能指标
* 确定期望的结果：通过测试来证明or确认某个结果。
* 根据测试类型来决定具体测试步骤
  * 数据如何输入：仿真or实际？流量大小？
  * 测试结果：**可重复才能展现实际的效果。**
* 结果分析&优化后重复测试

## 测试工具

常见测试场景对应的不同测试工具

* web：JMeter（java）、LoadRunner、Locust（Python）
* 系统：UnixBench、perf
* 数据库：SysBench、mysqlslap
* IO: ioZone
* 网络：Netperf
* 移动app：不同生态系统不同。

## 保证结果可靠&可重复

* 详细记录测试环境及过程：软硬件版本、操作系统、负载、使用数据等。
* 每次测试之后能够快速复位。
* 负载请求的输入数据足够，不会影响性能。
* 适当输出日志：CPU使用率等等，用作后期分析。
* 测试环境需要保持一致且稳定。

# 性能分析

* 性能问题实质：某个资源受到制约。

## CPU

现在Cpu普遍采用多处理器Socket 来提高CPU性能。每个处理器都自己可以直接访问的本地内存。处理器之间可以互相访问内存，这样耗时较大。

* NUMA-non uniform memory access：socket 自己访问自己的本地内存+访问其他socket的内存。

* **多级缓存L1、L2、L3**
  * 级别越小，越接近CPU,速度越快，但容量也越小。
  * L3被在同一个socket当中的核共享。
  * L1: L1d cache【L1 Data Cache】    L1i cache【L1 instruction cache】
* 超线程 Hyperthreading，HT：一个核分为几个逻辑核，实现多线程。
  * 一个核分为几个超线程：intel 一般是2，根据CPU架构不同而变化。
  * CPU 总数 = socket * core * HT 

## 内存-减少延迟，提高分配效率

​        性能指标：缓存命中率、缓存一致性、内存带宽、内存延迟、内存使用大小及碎片、内存分配和回收速度等。

* 缓存&缓存命中率：CPU与内存数据交换器，解决两者速度不匹配而导致的矛盾。

  逐级增大缓存原因：提高各级缓存命中率，降低直接访问内存的概率，提高效率。

* 缓存一致性cache coherence：确保每个核的L1、L2缓存一致，否则运算造成错误结果。

* 内存带宽和延迟：单位时间内可以并行读写内存的数据量为内存带宽，通常：字节/s。该值一般为理论值，实际代码只能达到最大带宽利用率的60%

* 内存分配：尽量对内存使用大小进行调优，尽可能少使用内存，提高效率。

## 网络

​       性能指标：可用性ping、响应时间、网络带宽容量、网络吞吐量、网络利用率。

* 若部署在不同服务器中的两个服务，若数据交换很多，则尽量在一个机柜当中，即使不能再一个机柜，也要尽量在一个PoD内部，否则网络带宽对服务性能影响极大。

# 性能优化

**策略**

* 时间换空间【压缩算法-比例、速度、内存上考虑】/空间换时间【能存的预先存储】
* 并行、异步操作：asyncio
* 提前处理、延后处理
* 缓存数据和结果
* 合并&批处理：flink
* 算法设计、数据结构优化

**SSD损耗**

* 每个SSD都有固定数量的擦除周期，若在短时间内写到SSD太多数据，就会导致SSD损耗太快。

**最大可接受延迟**

* 200ms

# 具体实践

## 生产环境进行真实容量测试

* 容量预测：确保服务容量足够，因此需要做容量的性能测试---单台*n 等于全部性能

具体步骤

* 生产环境流量重定向:重定向可能会影响真正客户，因此需要合理的重定向机制【非入侵性检测，真实流量按照百分比进行重定向】
* 测试时间不能过短【没有效果】or过长【影响用户】

## 规划和控制数据库的复制延迟大小

背景：数据库复制延迟太大会导致生产事故【一个用户更新了自己的照片，但朋友却迟迟看不到，导致广告投放量等与钱相关的统计出现统计错误。】

* 数据库复制延迟：当线上服务需要多个数据库时，一条信息从源头数据库传递复制到下游数据库时经过的延迟。
* 数据的复制和传输：隔离数据库和数据使用者，可通过分级分散用户流量，提高系统扩展性。【延迟可接受的情况下】

需要考虑的点：

* 未来流量预测
* 数据复制延迟的预测
* 数据复制容量确定

**解决方案**

* 对于未来可能增加的流量---通过消费队列进行缓冲。




------

