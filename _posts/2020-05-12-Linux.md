---
title: 'linux-notes'
date: 2020-06-15
permalink: /posts/2020/06/linux-notes/
tags:
  - cool posts
  - category1
  - category2
---

Some linux usage experience.

# 常用客户端工具

## mobaXterm

破解版可无限保存ssh记录

### 问题记录

* linux 服务器连接断开

  * 修改 /etc/ssh ssh_config 与 sshd_config 区别

    ssh_config 是针对客户端的配置文件  &  Sshd_config 是针对服务器的配置文件

  *  sshd_config 可以配置是否需要密码登录：PasswordAuthentication yes

* ssh 连接报错：Network error software caused connection abort

  * vim /etc/ssh/sshd_config 
  * 找到 TCP KeepAlive yes 把前面的 # 去掉
  * 找到ClientAliveInterval 参数去掉前面的#【该参数指定了服务器端向客户端请求消息的时间间隔，默认是0，不发送。ClientAliveInterval 60 表示每分钟发送一次，然后客户端相应，这样就保持长连接，比较奇怪的地方是，这里需要服务器主动发出请求，而不是客户端。正常情况下，ClientAliveCountMax】

# 文件操作命令

* 统计某文件中某内容出现次数：grep -o 内容 文件名 \| wc -l
* 统计某文件行数：wc -l 文件名
* 查看某文件中某内容对应的行：grep -n "内容" 文件名
* 复制文件：cp 当前文件路径 新复制文件路径 
* 将某个文件前m行移到另一个文件中：head -m a.txt > b.txt
* 删除文件/文件夹
  * 删除文件：rm -f 文件路径
  * 删除文件夹：rm -rf 文件夹路径 
* 移动/重命名文件
  * 重命名文件：mv 当前文件名称 重命名名称
  * 移动文件到目标路径，询问是否覆盖重复文件：mv -i 当前文件路径 目标文件路径
  * 移动文件到目标路径，直接覆盖重复文件：mv -f 当前文件路径 目标文件路径
  * 移动文件到目标路径，备份目标路径重复文件：mv -b 当前文件路径 目标文件路径

* 文件解压
  * tar.gz 文件：tar -zxvf Python-3.8.5.tgz
  * .zip 文件： unzip 文件名
  * unrar e xxx.rar

* 查看文件第n行内容：
  * 第1行：head -n 1 文件名
  * 第m行： head -m 文件名 

* 文件编辑：vim
  * 进入并编辑：cd到指定目录    vim 文件名     按insert 或 i 之后开始编辑
  * 退出：先按ESC之后      直接退出（：q）强制退出（：q!）保存并退出（：wq）
  * **切换到编辑模式在复制粘贴文件**：按照1）vim 进入之后   按i（进入编辑模式）ctrl+c/v

* 文件or 日志搜索（关键词匹配）：tail -f 
  * 实时刷新日志：tail -f 文件名 \| grep 关键词
  * 实时刷新日志的最新100行：tail -100f 文件名 \| grep 关键词

* 传文件/文件夹: scp
  * 远程服务器上的文件复制到本机: scp root@ip:/path/ /localpath
  * 远程服务器上的文件夹复制到本机：scp -r root@ip:/path/ /localpath
  * 本地文件复制到远程服务器：scp /localpath root@ip:/path
  *  本地文件夹复制到远程服务器：scp –r /local/path root@ip:/path
  *  直接从本地电脑上传文件到远端服务器：scp -p 9854 /cygdrive/待上传文件本地目录 root@localhost：/上传的目标路径
* vim 之后删除某一行：在esc状态下，直接dd，表示删除当前行。

# 进程相关

​      当iowait升高，进程可能因为得不到硬件响应而长时间处于不可中断状态。从PS或top命令的输出中可以发现，他们都处于D状态（不可中断状态）。

**进程包含的状态**

* R：Running/Runable, 进程在CPU就绪队列中，正在运行或正在等待运行。
* D：Disk Sleep，不可中断的睡眠状态，一般表示进程正在跟硬件交互且交互过程不允许被其他进程打断或中断打断。
* Z：Zombie，僵尸进程，进程实际已结束但父进程还未回收资源（描述符、pid等）
* S：Interrupt Sleep，可中断睡眠状态，进程因为等待某个事件而被系统挂起，事件发生时会被唤醒进入R状态。
* I：Idle，空闲状态，用于不可中断睡眠的内核线程上。
* T/t: Stopped 或 Traced，进程处于暂停或跟踪状态。向进程发送SIGCONT信号进程会恢复运行。【使用调试器调试代码时，使用断点进程也会变成跟踪状态。】
* X：Dead，进程已死亡，不会在top或ps中看到它。
* Ss+：第一个s表示可中断睡眠状态，第二个 s 和 + 表示这个进程是一个会话的领导进程，而 + 表示前台进程组。
  * 进程组：一组相互关联的进程，比如每个子进程都是父进程所在组的成员。
  * 会话：共享同一个控制终端的一个或多个进程组。

**进程操作命令**

* PS查看进程状态：ps -ef\|grep 进程字段or文件名（eg: ps -ef\|grep python3)

  执行后的参数说明例子：

  | 用户名 | pid    | child_pid | CPU占比 | 进程开始时间 | \    | 使用CPU时间 | 进程名  | 文件名 |
  | ------ | ------ | --------- | ------- | ------------ | ---- | ----------- | ------- | ------ |
  | root   | 进程号 | 进程号    | cpu占比 | 具体时间     | \    | 具体时间    | python3 | a.py   |

* 杀死、批量杀死进程

  * 杀死某个进程：kill -9 pid
  * 正常退出某个进程：kill -15 pid
  * 批量杀死某文件名对应的所有进程（cd 到文件所在路径后）：pkill -f 文件名 

* 后台不挂断运行代码：nohup

  * nohup 可以不挂断同时执行多个代码  & 执行后的打印全部存入nohup.out文件，一直积累不自动删除

  * 命令格式：nohup 解释器 文件名 & (eg:nohup python3 new_main.py & 或 nohup java -jar xxx.jar &）

  * 输出重定向：nohup 输出重定向到 /dev/null() 后不会产生 nohup.out 文件

    ​    eg: nohup python3 new_main.py >/dev/null 2>&1 & 

* 查看后台运行任务：jobs -l 

* 查找某个进程pid：pidof python3

* 最大进程数：sysctl kernel.pid_max

## 僵尸进程

**子进程正常创建逻辑**

* 当一个进程创建子进程后，它应该通过系统调用 wait() 或者 waitpid() 等待子进程结束，回收子进程的资源。

* 子进程在结束时，会向它的父进程发送 SIGCHLD 信号。父进程可以注册 SIGCHLD 信号的处理函数，异步回收资源。

* 若父进程没这么做or子进程执行太快，父进程还没来得及处理子进程状态，子进程就已经提前退出，那这时的子进程就会变成僵尸进程。

* 通常，僵尸进程持续时间都比较短，在父进程回收它的资源后就会消亡；或者在父进程退出后，由 init 进程回收后也会消亡。【若父进程没有处理子进程的终止，那么子进程就会一直处于僵尸状态。大量的僵尸进程会用尽 PID 进程号，导致新进程不能创建】

* 统计僵尸进程命令：ps -ef | grep defunct | grep -v grep | wc -l

# 系统资源查看命令

* 端口占用：netstat –anp\|grep 端口号
* 端口是否已对外开放: netstat -ntulp \| grep 端口号
* 指定端口是否已开放：firewall-cmd –query-port=666/tcp（yes 已开启）
* cpu信息：lscpu
* linux 系统版本号：cat/proc/version
* 服务器cpu数
  * 物理CPU：cat /proc/cpuinfo\|grep “physical id”\|sort –u\|wc –l
  * 每个物理CPU中的核数：cat /proc/cpuinfo\|grep “cpu cores”\|uniq
  * 逻辑cpu：cat /proc/cpuinfo\|grep “processor”\|wc -l
  * Cpu名称型号：cat /proc/cpuinfo\|grep “name”\|cut –f2 –d:\|uniq

* 内存占用

  * 最大命令：free -h   【free -h -s 2 每2s自动执行一次该命令】

  * 某个进程的内存占用：ps -aux\|grep python3(进程名)

  * 更详细的内存占比： cat /proc/进程号/status: VmRSS为进程所占用的内存

  * top命令，之后按M：所有进程按照内存占用大小排序

    top 命令，之后按P：所有进程按照CPU占用排序。
    
    * VIRT：进程虚拟内存大小，只要是申请过的内存，即使还未被分配，也会被算在内。
    * RES : 常驻内存大小，即实际使用的物理内存大小，不包括swap和共享内存。
    * SHR: 共享内存大小。
    * %MEM：进程使用物理内存占系统内存的百分比。

* 磁盘占用情况：df 

  执行之后可以用于查看具体文件的占用

  * 返回根目录：cd /
  * 确认具体那个文件占用磁盘较大：du -h -x --max-depth=1

​         PS: df -h 没有发现大文件之后的查询思路：**lsof -n grep deleted**，找到对应进程号后杀掉[参考](https://www.cnblogs.com/muchengnanfeng/p/9554993.html)

* 进程运行在哪个逻辑CPU上：ps -eo pid，args，psr \|grep nginx
* linux 下的python console 交互
  * 查看当前python连接：ll /usr/bin/grep python
  * 进入命令行模式：python3
  * 退出命令行模式：ctrl+D

## 系统资源查看工具

### dstat

同时查看CPU 和 I/O的情况。





# 网络相关命令

## 基本命令

* 通断性：ping ip （python 多目标异步发送icmp包进行ping的库：multiping）
* 网络跳数：traceroute ip/域名
  * 说明：通过向目标主机发送一条消息并通过会带来判断主机状态，遍历由源主机到目的主机的交互线路上所有的路由器并判断状态，一般以30为最大TTL，即以该线路上不超过29台路由器为前提进行遍历。
  * 基本原理：当路由器收到一份IP数据报，若该报文的ttl字段是1，则该报文的生存周期消耗殆尽，本路由处理后还未到达目标主机则需要将该数据丢弃，并给信源主机发送一份ICMP超时报文（包含中间路由器地址），这意味着：通过发送一份TTL字段为n的IP数据报给目的主机，就得到了该路径中的第n个路由器的IP地址，那么我们使IP数据报的TTL字段值从1开始递增，就可以获得所有中间路由的IP地址。由于已经到达目的主机，因此不会再发送ICMP应答报文，通过区分收到的ICMP报文是超时报文（type = 11）还是应答报文（type = 0）以判断程序应该何时结束。[每一次发包ttl从1开始增加，在一次traceroute过程当中，从源主机出发，每次经过1个路由则ttl-1，为0时返回本次所有路由状态，然后进入下一次发包。]
  * **最大30跳**，每个记录1跳，每一跳表示一个网关，3个时间表示发送的三个包网关相应后的返回时间。 

* mtr命令：（ping+traceroute)

  * 命令格式：mtr ip

  * <img src='/images/img/mtr示例.png'>

    查看traceroute 路径，丢包率，平均解析时延等，通过这条命令结合实际情况观察路径上的丢包情况等。

* 网络是否通畅\|：\| ip

  * 通过url执行上传或下载

  * \| --h  查看help 文件命令执行方式。

  * \| --k  跳过ssl 认证环节。

  * \| –data-urlencode()  url 编码的数据

  * \| url：port/path  查看当前路径内容。

    使用示例

  * \| –k https://ip:443

* bgpdump：linux解析bgp报文命令，[安装步骤](https://blog.csdn.net/weixin_35708669/article/details/89442180)

* iptable

  ifconfig 确定网卡名称后

  * 53的tcp 和 udp **重定向**到5053

    iptables -t nat -A PREROUTING -i enp125s0f0 -p tcp --dport 53 -j REDIRECT --to-ports 5053

    iptables -t nat -A PREROUTING -i enp125s0f0 -p udp --dport 53 -j REDIRECT --to-ports 5053

  * 查看iptable 规则：iptables -t nat -L -v -n

  * 删除某条规则

    规则行号：iptables -t nat -L -n --line-numbers

    根据num行号确定删除规则： iptables –t nat –D INPUT 第几条规则

​              PS: 若报错iptables：index of deletion too big，则需要明确要删除的表（ iptables -t nat -D PREROUTING 第几条规则）

* 防火墙操作

  * 查看防火墙状态: systemctl status firewalled

  * 开启防火墙：systemctl start firewalled // service firewalled start

  * 关闭防火墙：systemctl stop firewalled

    若遇到无法开启防火墙的情况

  * 先 systemctl unmask firewalled.service

  * 再 systemctl start firewalled.service

* telent：telnet ip port

* ifconfig： 查看网卡信息 & 确认ip等内容

  * 服务器若出现ping不同网关等情况：1）背后网线没插对口 2）ifconfig 后出现了类似于“brixxx”开头的网卡，ifconfig brixxxx down 停用后解决。

## Linux网络监控&带宽查看

* ifconfig 确认网卡具体使用的哪一张
* ethtool 网卡名称：speed行为网卡带宽。
* 实时统计网卡带宽使用率：nload
* 实时监测网络状态：dstat -n

### iftop

实时观察带宽变化的工具，nethogs无法获得对应的pid【无法确认确实不占带宽还是其他情况】

**安装配置**

* 安装依赖：yum -y install flex byacc libpcap ncurses nc libpcap-devel
* 下载安装包：wget http://www.ex-parrot.com/pdw/iftop/download/iftop-0.17.tar.gz

* tar zxvf iftop-0.17.tar.gz
* cd iftop-0.17，执行命令配置：./configure --build=arm-linux
* make & make install 
* 执行iftop确认命令安装成功。

**字段含义及命令解析**

执行iftop后输出如下：

<img src='/images/img/iftop命令输出1.jpg'>

<img src='/images/img/iftop命令输出2.jpg'>

字段含义说明：

* 界面顶部：流量刻度尺，刻度分为五个大段显示，对应下面每行的白色横条
* 界面中部：
  * 最左边的 域名或ip表示当前服务器
  * 中间数据为“外部ip或域名”，=> 表示发送数据；<=表示接收数据。
  * 最右边3列为实时参数，表示“外部ip或域名”连接到当前服务器的2s，10s和40s内的平均流量值。
  * 白色横条（每行从最左边开始的白色横条）：对流量大小进行动态展示，以头部刻度尺为基准，通过这个流量图形条可以看出哪个ip流量最大，定位网络问题。
* 界面底部：
  * TX: 发送数据。
  * RX: 接收数据。
  * TOTAL: 发送和接收的全部流量。
  * cum：从运行iftop到目前的发送、接收和总数据量。
  * **peak：发送、接收及总的流量峰值。**【有时间限制】
  * rates：过去2s，10s，40s的平均流量。

**[命令参数示例](https://www.cnblogs.com/liulianzhen99/articles/17620576.html)**

* 显示特定网段的进出流量：iftop -F 106.11.79.0/24

  * 上述命令+将刻度尺设置为最大100M: iftop -F 106.11.79.0/24 -m 100M

* **每隔5s打印一次监听网卡流量信息（不实时监听），打印两次输出：**

  **iftop -i eth0 -n -t -s 5 -L 2**

* <u>**基于端口过滤：iftop -i enp125s0f0 -f 'port 53'**</u>

* 基于目的端口过滤：iftop -i enp125s0f0 -f 'dst port 53'

* 基于源端口过滤：iftop -i enp125s0f0 -f 'src port 53'

### nethogs

安装简单，可获得网卡中某个进程占用的带宽，但通过代码进行同步python测试，没有看到对应的pid出现。【无法确定是确实不占带宽还是什么情况】

**安装**

* yum install nethogs -y
* ifconfig 确定网卡后：nethogs 网卡

### sar

实时查看系统当前带宽信息，具体命令：sar -n DEV  1 【每隔1s输出一组网络收发报告数据】

# 其他命令

## crontab

### 说明

crontab 多用于linux下定时执行脚本

* linux 一般情况下自带crontab，可通过**查看crontab状态命令**来确认是否安装。

* cron 、crond、crontab：

  * cron: **the general name for the service** that runs scheduled actions

  * crond: **the name of the daemon** that runs in the background and reads crontab files.

  * crontab：a crontab is a file containing jobs in the format:

    ```
    minute hour day-of-month month day-of-week  command
    ```

**安装**

* ubuntu：
  * 安装：apt-get install cron
* centos：
  * yum install vixie-cron【vixie-cron软件包是cron的主程序】
  * yum install crontabs

**常用命令**: 命令中cron 和 crond可互换，具体区别见上，通常情况操作cron

* **查看crontab状态**：service cron status
* 启动：service cron start
* 重启：service cron restart
* 停止：service cron stop
* 检查状态：service cron status
* 查询cron 可用命令：service cron
* 重新载入配置：service crond reload
* centos 加入开机自启动：chkconfig --level 345 crond on

**基本语法**

crontab [-u user] file     |      crontab [-u user] [-i] {-e | -l | -r}

* -u user：指定user的时间表
* **-l：列出当前系统的时程表**
* -r：删除当前时程表
* -e：执行编辑器来设定时程表，内定vi编辑器

### 时间格式

**minute hour day-of-month month day-of-week  command**

* 上述5个值取值为*时表示，每分钟/小时/天... 都要执行。
* min: 取值范围0-59。当其值为a-b时，表示a-b分钟这段时间内都要执行；当其值为：*/n时，表示每间隔n分钟执行一次；当其值为a,b,c时，表示第a,b,c分钟要执行。
* hour：取值范围0-23，当其范围为a-b时，表示每天从第a-b小时都要执行；当其值为：*/n时，表示每间隔n小时执行一次；当其值为a,b,c时，表示第a,b,c小时要执行。
* day-of-month：1-31
* month：1-12
* day-of-week：0-6【周天为0】
* 也可以将所有设定放入文件中，用crontab file 来设定执行时间

| 执行时间                 | 格式           |
| ------------------------ | -------------- |
| 每分钟执行一次           | \* \* \* \* \* |
| 每小时执行一次           | 0 \* \* \* \*  |
| 每天执行一次             | 0 0 \* \* \*   |
| 每周执行一次             | 0 0 \* \* 0    |
| 每月执行一次             | 0 0 1 \* \*    |
| 每月最后一天定时执行一次 | 0 0 L \* \*    |
| 每年执行一次             | 0 0 1 1 \*     |

**实例**

* 每分钟执行一次/bin/ls:   \* \* \* \* \* /bin/ls

* **每周执行一次 python脚本：0 0 \* \* 0 python3 /opt/wjt/main.py**

* 在 12 月内, 每天早上 6 -12 点，每隔 3 个小时 执行一次 /usr/bin/backup：

  0 6-12/3 * 12 * /usr/bin/backup

* 周一到周五每天下午 5:00 寄一封信给 alex@domain.name：0 17 * * 1-5 mail -s "hi" alex@domain.name < /tmp/maildata

PS: crontab 当程序在指定时间执行后，系统会发送一封邮件给当前用户，显示该命令执行内容，**若不希望收到类似邮件，在每一行最后空一格加上\> /dev/null 2>&1**

### 配置文件

* 全局配置文件：/etc/ 下 
  * 每天/周/月/小时需要执行的任务：cron.daily  cron.weekly  cron.monthly  cron. hourly  
  * 系统定期执行的任务：cron.d

### 用户自行配置任务

* 查看当前的时程表：crontab  -l

* 编辑crontab时程表：crontab -e

  * **完成编辑后，保存并退出：ctrl+x,按提示输入Y N 是否保存写入，enter【nano编辑器】**

* 查看系统日志中是否有相关定时任务日志：tail -f /var/log/syslog

  ```
  eg： CRON[pid]: (root) CMD (python3 /opt/wjt/test_cron.py)
  ```

* 重新启动crontab: service cron restart

* **停止任务：crontab -e 进入编辑界面后注释or删除掉后保存并退出。**

### 问题记录

* crontab 执行python3 xxxx.py 或执行了没输出【经过测试】

  * ubuntu查看crontab 系统日志： tail -f /var/log/syslog 【观察其中是否有相关定时任务的日志】

  * 问题定位：**crontab执行的定时python脚本中有：1）读取配置文件  2）读写文件的动作。一般定时任务都不会执行.** 

    ps: 脚本在执行时,由于是通过crontab去执行的,他的执行目录会变成当前用户的home目录,如果是root,就会在/root/下执行.

  * 解决方案：将执行的python命令放到shell脚本里，然后crontab 定时执行.sh 文件

    * 新建一个shell 脚本： run.sh
    * 开放权限：chmod +x run.sh
    * crontab 每分钟执行：\* \* \* \* \* /bin/sh /opt/wjt/run.sh

## ssh 建隧道

* 建隧道例子：ssh -f -N -L 9988:211.144.18.3:20022 root@10.42.25.13  
  *  将跳板机（211.144.18.3：20022）通过9988端口映射到本地13
  * ssh -f -N -L 9854:172.20.10.46:22 common@localhost -p 9988 
  * 将通过跳板机连接的目标服务器（172.20.10.46:22）通过9854端口映射到跳板机的端口9988，进而映射到本地

* 直接从本地电脑上传文件到远端服务器---完成上述映射之后: scp -p 9854 /cygdrive/待上传文件本地目录 root@localhost：/上传的目标路径

* 跳板机（13）传文件到远程目录下
  *  文件传到13 root 目录下
  *  scp -P 20022 dnspython.conf common@211.144.18.3:/home/common
  * 控制节点 /home/common 再scp

## 任务绑定CPU

当多个进程争抢一个CPU资源（或1个CPU资源分配了多个进程，前几个进程执行时资源耗尽）导致代码耗时不稳定，[参考](https://blog.csdn.net/qq_30683329/article/details/88779390)

* CPU 亲和力：CPU affinity是一种调度属性(scheduler property), 它可以**将一个进程"绑定" 到一个或一组CPU上**.在SMP(Symmetric Multi-Processing对称多处理)架构下，Linux调度器(scheduler)会根据CPU affinity的设置让指定的进程运行在"**绑定"**的CPU上,而不会在别的CPU上运行。**Linux调度器同样支持自然CPU亲和性(natural CPU affinity): 调度器会试图保持进程在相同的CPU上运行, <u>这意味着进程通常**不会在处理器之间频繁迁移,进程迁移的频率小就意味着产生的负载小。</u>

  因为**程序的作者比调度器更了解程序,所以我们可以手动地为其分配CPU核，而不会过多地占用CPU0，或是让我们关键进程和一堆别的进程挤在一起,**所有设置CPU亲和性可以使某些程序提高性能。

* CPU核心表示方法

  CPU affinity 使用位掩码（bitmask）表示，每一位都表示一个CPU

  最低位表示第一个逻辑CPU,最高为表示最后一个逻辑CPU

  CPU affinity 典型的表示方法是使用16进制：

  1）0x00000001   is processor #0

  2）0x00000003   is processors #0 and processor #1

  0Xfffffffff      is all processors

* 如何确定绑核成功

  top命令 -> F -> last used CPU ->ESC ->退回正常top界面，就可以看到哪些进程泡在哪些核上，若lastCPU一直保持不动，则绑核成功。

* Taskset 使用方法

  通过该命令，可以将一个启动的进程直接绑定在某个核上运行。

  * 命令格式taskset-cp cpu(cpu-list) pid

    eg：taskset -cp 1(1-3) 1927 将进程号为1927的进程绑定在核1/1-3上

  * taskset -h 查看具体参数说明

# 操作系统

centos、debian等操作系统使用时遇到的问题记录

## Debian 装GUI图形界面

* sudo su –
* 更新debian系统： apt update & apt –y upgrade
* GNOME 使用一下命令安装桌面环境【耗时】：apt –y install task-gnome-desktop
* 上一步完成后，分配graphical runlevel：systemctl set-default graphical.target
* 默认情况通过GNOME 显示管理器GDM禁用root用户登录，去掉限制：
  * vi /etc/pam.d/gdm-password
  * 注释掉：# auth  required pam_succeed_if.so user !=root quite_success
* 重启debian服务器：reboot
* 参考：搜索“如何为debian11安装图形用户界面GUI"

## Centos

### 修改最大链接数方法

* 暂时修改：ulimit -n 100001 【服务器重启后失效】

* 永久修改，[参考]( https://www.jianshu.com/p/1d3d368365bf)

  * vim /etc/security/limits.conf：在文件end of file 之后加上

    ```
    * soft nofile 65535
    * hard nofile 65535
    * soft nproc 65535
    * hard nproc 65535
    ```

  * ulimit -n： 查看确认最大链接数已被修改

### 问题记录

* centos yum 无法使用

  解决方案：/etc/yum.repos.d/ 下Centos-Base.repo 无法正常使用，需更新yum源，[参考](https://zhuanlan.zhihu.com/p/430561706)

* arm centos yum 无法正常使用---yum源只有x86

  解决方案：更新yum源，[参考](https://zhuanlan.zhihu.com/p/430561706)

## Linux

### 安装虚拟机

[参考](https://www.tecmint.com/install-vmware-workstation-in-linux/)

* 下载vmware workstation [安装文件](https://www.vmware.com/products/workstation-pro/workstation-pro-evaluation.html)

* 上传到15对应目录 /root/vmware/

* 修改权限否则报错: chmod a+x VMware…xx.boundle
* 安装: **./VMwarexxxxx.boundle**
* 启动vmware

# 系统配置相关

## /etc/hosts/

​      在通过服务器IP连接某个部署的文件或进程时，可直接使用IP 或 linux /etc/hosts/文件下写好的别名：

```
 vim /etc/hosts/
 --------------------
 ip 别名
```

## /dev/null

* /dev/null 称为空设备，是一个特殊的设备文件，它将丢弃一切写入其中的数据（但报告写入成功），读取该文件会立即得到一个EOF。类似于一个黑洞，常用于丢弃不需要的输出流。使用这些操作通常由重定向完成。

* 使用nohup 重定向的命令行方式： **nohup python3 new_main.py >/dev/null 2>&1 &**

## /etc/resolv.conf

若上述DNS配置文件无法解析DNS，则在**文件最后增加一个空格**：eg-- nameserver 8.8.8.8 

# shell 脚本

[参考内容](https://www.runoob.com/linux/linux-shell.html)

在一般情况下，人们并不区分 Bourne Shell 和 Bourne Again Shell，所以，像 **#!/bin/sh**，它同样也可以改为 **#!/bin/bash**

## 脚本运行

* cd 到脚本目录下后 执行 sh xxxx.sh
* 使用脚本绝对路径：sh /DNS/XXX.sh
* 增加权限后执行，cd到具体路径后：chmod +x ./test.sh #使脚本具有执行权限
* 将shell 脚本作为解释器参数运行（这种运行方式，不需要在第一行指定解释器信息， #！/bin/bash 这个）eg： /bin/sh test.sh              /bin/php test.php

## 脚本命令

* \#! 告诉系统其后路径所指定的程序即是解释此脚本文件的 Shell 程序。
* Shell 注释： 和python 一致，通过 # 注释
* echo 命令： shell 脚本的字符串输出命令，eg ：echo "Hello World !"，显示和输出命令
* shell字符串：单双引号，不用引号均可
  * 单引号：单引号当中的所有字符都会原样输出，单引号字符串引变量无效
  *  双引号：可以引变量，转义字符
* shell变量定义：不加美元符号定义，可重复定义已定义变量。
* 使用一个定义过的变量，只需要再其前面加美元符号即可： $
* **只读变量** 添加关键词 readonly 将变量定义为只读变量，只读变量的值不能被改变
* 脚本传参：执行shell 脚本向脚本传递参数，脚本内获取参数的格式： $n, n 为1个数字，1为执行脚本的第一次参数，2 为执行脚本的第二个参数

# CPU

## 平均负载

* **uptime**：系统负载情况查看命令：top、uptime【系统运行时间】

```
$ uptime
  09:10:23 up 2 days,20:14, 1 user, load average: 0.63,0.88,0.68
//当前时间 系统运行时间  正在登录用户数  过去1min，5min,10min 平均负载
```

**平均负载定义**

系统处于**可运行状态**和**不可中断状态**的平均进程数，即**平均活跃进程数**，和CPU使用率没有直接关系。

* 可运行状态：正使用或正等待CPU的进程。【PS命令处于R状态的进程】
* 不可中断状态：正处于内核态关键流程中的进程，且这些流程不可打断。【PS命令中看到D状态的进程，常见为等待硬件设备的I/O相应，不能】
* 最理想情况为一个CPU刚好运行一个进程【平均进程为2：2CPU机器刚好全被占用，4CPU机器50%空闲】

**合理值**

* 首先确定CPU个数：top  或 cat/proc/cpuinfo。
* 平均负载大于CPU个数时，数据过载。
  * 实际情况，平均负载高于70%CPU数量时，开始出现进程响应慢、影响服务正常功能等问题。
* uptime当中average load的三个值合理范围：
  * 若1min、5min、10min值相差不大，说明负载很平稳。
  * 若1min值远小于15min值，说明最近1min系统负载在减小，过去15min有很大负载。
  * 若1min值远大于15min，说明最近1min负载在增加，可能是临时性也可能是持续增加，一旦1min值超过CPU即为过载。

**平均负载&CPU使用率**

* 平均负载：单位时间内活跃进程数，不仅包括正在使用的CPU，还包括等待CPU和等待I/O的进程。
* CPU使用率：单位时间CPU繁忙情况的统计，不一定一致
  * CPU密集型进程：大量使用CPU导致平均负载升高，此时两者一致。
  * I/O密集型进程：等待I/O也会导平均负载升高，但CPU使用率不一定高；
  * 大量等待CPU的进程调度【上下文切换】：也会使平均负载升高，此时CPU使用率也会较高。

**平均负载升高分析命令**

linux自带的分析命令：top、ps、lsof【若无法联网安装其他工具】

mpstat、pidstat：sysstat 常用linux性能工具包中的两个命令。

* sudo apt install sysstat
* mpstat：常用多核CPU性能分析工具，实时查看每个CPU性能能指标及所有CPU平均指标【iowait】。【监测所有CPU&每5s输出一组数据：mpstat -P ALL 5 】
  * %usr：显示对应cpu的使用率。
  * %iowait：io等待占用率。
* pidstat：常用性能分析工具，实时查看进程CPU、内存、IO、上下文切换。【查询具体哪个进程导致CPU占用率为100%】间隔5s后输出一组数据：pid -u 5  1
  * %cpu：显示pid对应cpu的使用率。
  * %wait：进程等待CPU的时间比例。
  * Command：pid对应的命令。

## 上下文切换&如何排查

​       CPU 上下文切换，是保证 Linux 系统正常工作的核心功能之一，一般情况下不需要我们特别关注。但过多的上下文切换，会把 CPU 时间消耗在寄存器、内核栈以及虚拟内存等数据的保存和恢复上，从而缩短进程真正运行的时间，导致系统的整体性能大幅下降。

​      多进程竞争CPU产生CPU上下文切换导致延时&负载上升。

* Linux 多任务操作系统，支持任务数量远大于CPU数量，通过操作系统轮流将任务分配给各CPU模拟多任务同时运行。
* 每个任务运行前，需要系统设置好**CPU寄存器和程序计数器**用于加载任务。
* **CPU上下文**：CPU寄存器&程序计数器都是在CPU运行任何任务前必须依赖的环境。
* **CPU上下文切换**
  * 保存前一个任务的CPU上下文，加载新任务上下文到寄存器和程序计数器，最后跳转到程序计数器所指新位置，运行任务。 
  * 保存下来的上下文会存储在系统内核中，在任务重新调度执行时再次加载，保证状态&连续运行。
  * 3类常见"任务"：进程、线程、**中断**

### 进程上下文切换

​       根据[ Tsuna ](https://blog.tsunanet.net/2010/11/how-long-does-it-take-to-make-context.html)测试报告，**每次上下文切换需要ns级到微秒级 CPU 时间。**在进程上下文切换次数较多时，容易导致 CPU 将大量时间耗费在寄存器、内核栈以及虚拟内存等资源的保存和恢复上，进而大大缩短真正运行进程的时间，导致平均负载升高。

​       linux 按照权限将进程运行空间分为内核空间Ring0&用户空间Ring3。

* 内核空间Ring0：具有最高权限、可直接访问所有资源。
* 用户空间Ring3：只能访问受限资源，不能直接访问内存等硬件设备，必须通过系统内核调用后才能访问。

​      进程从用户态到内核态需要通过**系统调用**来完成。系统调用本身也存在上下文切换【执行不同调用命令都需要先加载指令位置】。

* **<u>用户态</u>**：进程在用户空间运行时。
* **<u>内核态</u>**：进程在内核空间运行时。进程由内核管理调度，**进程切换只能发生在内核态**。
* **一次系统调用，发生两次CPU上下文切换**:切过去之后还要恢复。

* **进程上下文**：不仅包括了虚拟内存、栈、全局变量等用户空间的资源，还包括了内核堆栈、寄存器等内核空间的状态。【因此，进程上下文切换就比系统调用多一步：在保存当前进程内核状态和 CPU 寄存器前，先把该进程的虚拟内存、栈等保存下来。加载了下一进程的内核态后，还需要刷新进程的虚拟内存和用户栈。】

**进程上下文切换时间**

* 在进程切换时才需要切换上下文。
* 每个 CPU 维护一个就绪队列，将活跃进程（即正在运行和正在等待 CPU 的进程）按照优先级和等待 CPU 的时间排序，**选择优先级最高和等待 CPU 时间最长的进程来运行。**

**进程被调度到CPU上运行的情况**

* 公平调度：CPU时间划分为时间片，轮流分配各个进程，分配时间耗尽时，切换下一个进程。
* 系统资源不足时，当前进程挂起，调度其他进程运行。
* 优先级更高进程出现时，当前进程挂起，保证优先级更高进程运行。
* 硬件中断时，执行内核中断服务程序。

### 线程上下文切换

* **线程：调度基本单位，**内核中任务调度实际调度对象是线程。

* **进程：资源拥有基本单位**，给线程提供虚拟内存、全局变量等资源。

  **<u>同一个进程中的各个线程资源共享，不同进程中的线程资源不共享</u>**

**线程切换具体情况**

* 前后两个线程属于不同进程：因为资源不共享，所以切换过程等价于进程上下文切换。
* 前后两个线程属于相同进程：因为资源共享，所以切换时虚拟内存等资源保持不变，**需要保存后切换的为：私有数据、寄存器等不共享数据。**

Conclusion：**同进程中线程上下文切换消耗更小**【多线程代替多进程的优势】【**python因为GIL的存在，多线程实际是单进程，多进程才能避开GIL实现真正并发**】

### 中断上下文切换

* 快速响应硬件事件：打断进程正常调度和执行，转而调用中断处理程序。【打断时需要保存被打断进程状态以便恢复】
* 中断比进程有更高优先级。

### 查看系统上下文切换情况-vmstat

```
$vmstat 5 # 每隔5s输出一组数据
procs    ---memory---       -swap- --io-- -system--  ---cpu---
r  b  swpd free buff cache  si so  bi bo in   cs     us sy id wa st
0  0  0    1024 1024 1024   0  0   0  0  25   33     0   0 100 0  0
```

其他部分可以根据意思确认，主要关注以下4列

* **CS: context switch 每秒上下文切换次数。**
* in：interrupt 每秒中断的次数。
* r：Running or Runnable 正在运行or等待CPU的进程数。
* b：Blocked处于不可中断睡眠状态的进程数。

**pidstat：加上-w选项，可以查看每个进程上下文切换情况**

```
$ pidstat -w 5
linux 4.15.0 ubuntu 09/23/18 _x86_64_ (2cpu)
09:03:31   UID   PID   cswch/s nvcswch/s Command
09:04:33   0     1     0.20    0.00      systemd
```

两行重点关注对象

* cswch：每秒自愿上下文切换【进程无法获取所需资源导致的上下文切换】
* nvcswch：非自愿每秒上下文切换次数。【进程时间片已到等原因被系统强制切换】

**根据cpu性能，上下文切换次数在1w以内比较稳定。**

- 自愿上下文切换变多，说明进程都在等待资源，有可能发生了 I/O 等其他问题；
- 非自愿上下文切换变多，说明进程都在被强制调度【争抢 CPU】，说明 CPU 的确成了瓶颈；
- 中断次数变多，说明 CPU 被中断处理程序占用，查看 /proc/interrupts 分析具体的中断类型。

## CPU使用率

**节拍率**

* 为了维护 CPU 时间，Linux 通过事先定义的**节拍率**（内核中表示为 HZ），触发时间中断，并使用全局变量 Jiffies 记录了开机以来的节拍数。每发生一次时间中断，Jiffies 的值就加 1。

* 节拍率 HZ 是内核可配选项，可以设置为 100、250、1000 等，通过查询 /boot/config 内核选项来查看它的配置值。【eg：节拍率设置为 250，也就是每秒钟触发 250 次时间中断。】
* 因为节拍率HZ是内核选项，所以用户空间无法直接访问【内核向用户空间提供了一个用户空间节拍率USER_HZ,固定为100，也就是1/100s】

**CPU统计信息查看命令**:  cat/proc/stat|grep ^cpu

**CPU使用率=（1-空闲时间/总CPU时间）**

* 实际计算中，性能工具一般会计算：间隔一段时间的两次值作差后的这段时间平均CPU使用率。

**CPU使用率的具体查看**

* top：系统总体CPU和内存使用情况&各个进程资源的使用情况。
* ps：每个进程的资源使用情况。
* pidstat：区分用户态和进程态【%usr-用户态CPU使用率；%system-内核态CPU使用率；%guest-运行虚拟机CPU的使用率;%wait-等待cpu使用率；%CPU-总cpu使用率】

**CPU使用率过高**

*  top、ps、pidstat 等工具能找到 CPU 使用率较高（比如 100% ）的进程。
* 寻找具体占CPU高的函数：
  * GDB（The GNU Project Debugger）：找到大致函数后中断调试。
  * **perf：**以性能事件采样为基础，可以线上使用。
    * **<u>perf top: 类似top，实时显示占用CPU时钟最多的函数或指令，查找热点函数。</u>**   [perf top -g -p pid]   -g 开启调用关系分析， -p指定进程号
    * perf record/perf report: 实时展示性能及是否保存。

**CPU使用率过高但找不到高CPU应用的情况**

启动服务后，发现系统CPU占用较高，但top、pidstat命令直接观察CPU相关参数，没有发现占用CPU较大进程的情况。

* 观察实际业务与top中进程状态是否为R（运行）或S（sleep）判断实际占用CPU的进程。

## 某进程pid不停改变可能的情况

**若top观察发现某个进程pid不停改变**，可能的情况有如下几种：

* 1st：进程不停崩溃重启---进程在退出后被监控系统自动重启【supervisor】
* 2nd：进程都是短时进程，一般只运行极短时间就结束，很难用top发现。

**查找父进程命令pstree**

```
$ pstree | grep 进程名
```

通过输出的进程调用关系，进入对应的源码中，找到这部分调用的源码进一步判断。

## execsnoop-短时进程性能查询工具

通过ftrace实时监控进程的exec()行为，并输出短时进程的基本信息，包括PID、父进程PID、命令行参数及执行结果。

```
$ execsnoop
输出结果包含所有短时启动的进程
```

**小结**

CPU 使用率是最直观和最常用的系统性能指标，更是我们在排查性能问题时，通常会关注的第一个指标。 比如：

- 用户 CPU （%user）和 Nice CPU （%nice）高，说明用户态进程占用了较多的 CPU，所以应该着重排查进程的性能问题。
- 系统 CPU 高，说明内核态占用了较多的 CPU，所以应该着重排查内核线程或者系统调用的性能问题。
- I/O 等待（%iowait） CPU 高，说明等待 I/O 的时间比较长，所以应该着重排查系统存储是不是出现了 I/O 问题。
- 软中断（%softirq）和硬中断（%irq）高，说明软中断或硬中断的处理程序占用了较多的 CPU，所以应该着重排查内核中的中断服务程序。
- 当碰到无法解释的 CPU 使用率问题时，先要检查一下是不是短时应用在捣鬼。【短时应用的运行时间比较短，很难在 top 或者 ps 这类展示系统概要和进程快照的工具中发现，你需要使用记录事件的工具来配合诊断，比如 execsnoop 或者 perf top。】

## 中断

* 除了iowait，软中断softirq CPU使用率升高也是最常见的一种性能问题。

* 中断实质：异步事件处理机制，可以提高系统的并发处理能力。【尽可能快的处理完毕，减少对正常进程的影响】
* 中断处理程序在响应中断时，还会临时关闭中断。这就会导致上一次中断处理完成之前，其他中断都不能响应，也就是说中断有可能会丢失。

**软中断**

为解决中断执行过长和中断丢失的问题，linux将中断分成上下半部：

* 上半部【硬中断】：快速处理中断，中断禁止模式下运行，处理和硬件相关or时间敏感的工作。
  * 
* 下半部【软中断】：延迟处理上半部未完成的工作，以内核线程的方式运行。
  * 每个cpu对应一个软中断内核线程，名字为：**“ksoftirqd/0”**
  * 一些内核自定义事件也属于软终端【内核调度、RCU锁等】

**软中断查看命令&内核线程查看命令**

* 软中断运行情况：cat /proc/softirqs
  * 上述命令能够看到各种类型中断在不同CPU上的累计运行次数。
* 硬中断运行情况：cat /proc/interrupts 

## 快速分析CPU瓶颈套路

CPU性能-根据指标找工具

| 性能指标          | 工具                                 | 说明                                                         |
| ----------------- | ------------------------------------ | ------------------------------------------------------------ |
| 平均负载          | uptime 、top                         | uptime最简单 、top更全面                                     |
| 系统整体CPU使用率 | vmstat、mpstat、top、sar、/proc/stat | top、vmstat、mpstat仅支持动态查看，sar还可以输出历史数据，/proc/stat 数据来源 |
| 进程cpu使用率     | top、pidstat、ps                     | top、ps按cpu使用率给进程排序，pidstat显示实际使用了cpu的进程 |
| 系统上下文切换    | vmstat                               | 上下文切换次数&运行状态和不可中断状态进程数量                |
| 进程上下文切换    | pidstat                              | -w 选项参数需要加上                                          |
| 软中断            | top、/proc/softirqs                  | /proc/softirqs 提供各种软中断在cpu上运行的累计次数；top提供软中断CPU使用率 |
| 硬中断            | vmstat、/proc/interrupts             | /proc/interrupts提供各种应中断在cpu上运行的累计次数          |
| 网络              | iftop、tcpdump                       | 网络收发、带宽等 & 抓包情况                                  |
| I/O               | dstat、sar                           | 都提供I/O整体情况                                            |
| CPU               | /proc/cpuinfo                        | lscpu更直观                                                  |
| 事件剖析          | perf                                 | 分析cpu缓存及内核调用                                        |

# 内存

通常情况下的内存：物理内存【主存（动态随机访问内存DRAM）】

* 只有内核才可以直接访问物理内存，进程访问的是虚拟内存。
* 虚拟空间=内核空间+用户空间【不同字长的处理器地址空间范围不同】

​       PS: 进程用户态访问用户空间，内核态访问内核空间。(每个进程地址空间都包含了内核空间，但这些内核空间都是相同的物理内存。因此虚拟内存大于分配的物理内存，只有实际使用虚拟内存的进程才会分配物理内存，通过内存映射来管理。

* **内存映射**：将虚拟内存地址映射到物理内存地址。内核为每个进程维护一张页表，记录虚拟地址和物理地址的映射关系。
  * 页表实际存储在CPU内存管理单元MMU中，确保CPU通过硬件找到要访问的内存。
  
  * MMU不以字节为单位来管理内存，而是规定一个内存映射最小单位（页），通常4kB，每次内存映射，都需要关联4KB整数倍内存空间。
  
  * 对于页表项过多的问题，linux提出两种解决方案：多级页表&大页。
  
    PS: 多级页表【内存分区管理，通过索引对内存块进行访问。】
  
    PPS:大页【比普通更大的内存块，通常用于使用大量内存的进程上，oracle，dpdk等】
  
* **虚拟内存空间分布**：从低到高分为五种不同内存段

  * 只读段：包括代码和常量。
  * 数据段：包括全局变量。
  * 堆：包括动态分配的内存，从低地址开始向上增长。
  * 栈：包括局部变量和函数调用的上下文。【固定8MB】
  * 文件映射段：包括动态库、共享内存等，从高地址开始向下增长。

## 内存分配与回收

* malloc() 是C标准库提供的内存分配函数，在系统调用上有两种实现方式：
  * brk()：减少缺页异常发生，提高内存命中率；工作繁忙时频繁释放内存会造成内存碎片，释放后不立即归还系统，缓存起来重复利用。【分配的内存在释放时不立即规划】
  * mmap（）：在释放时直接归还系统，每次mmap都会发生缺页异常；工作繁忙时，频繁内存分配会导致大量缺页异常【仅建议对大块内存使用mmap】
* 上述两种调用发生时没有真正分配内存，这些**内存都是在首次访问时分配【缺页进入内核，由内核分配】**
* linux 使用伙伴系统来管理内存分配：以页为单位管理内存，并通过相邻页合并，减少内存碎片化。
* 对内存来说，若只分配不释放就会造成内存泄露，因此在代码最后一定要调用：free() 或 unmap()

系统不会任由某个进程用完所有内存，在内存紧张时，会通过一系列方法回收：

* 回收缓存：Least Recently Used 回收最近最少的内存页面。
* 杀死进程：内存紧张时，通过OOM，直接杀掉大量占用内存的进程。
* 回收不常访问的内存，将内存通过交换分区swap直接写入磁盘。

**swap**

swap 其实就是将一块磁盘空间当做内存使用，将进程中暂时不用的数据存入磁盘（换出）；当进程访问这些内存时，再从磁盘读出这些数据到内存（换入）。

**OOM**

out of memory，内核保护机制，监控进程的使用情况，使用oom_score 为每个进程的内存使用情况进行评分。

* 一个进程内存消耗越大，oom_score 越大；
* 一个进程运行占用cpu越多，oom_score 越小；

用户内存空间包括多个不同的内存段，这些内存段为正是应用程序使用内存的基本方式。

* 栈内存：代码中定义一个局部变量， *int data[64]* ，就有了一个可以存储 64 个整数的内存段。由于这是一个局部变量，它会从内存空间的栈中分配内存。
  * **栈内存由系统自动分配和管理**。一旦程序运行超出这个局部变量作用域，**<u>栈内存就会被系统自动回收，不会产生内存泄漏的问题</u>**。
* 堆内存：若事先不知道数据大小，就需要标准库函数malloc() 在代码中**动态分配内存，此时系统会从<u>内存空间的堆中分配内存</u>。**
  * **堆内存由应用程序自己来分配和管理**。<u>**除非程序退出，堆内存并不会被系统自动释放，需要应用程序明确调用库函数 *free()* 来释放它们**</u>。如果应用程序没有正确释放堆内存，就会造成内存泄漏。
* 只读段内存：包括代码和常量。**因为只读，不会再去分配新内存，也不会产生内存泄露。**
* 数据段内存：包括全局变量和静态变量。**变量在定义时就已经确定了大小，所以也不会产生内存泄漏。**
* 最后一个内存映射段：包括动态链接库和共享内存。**共享内存由程序动态分配和管理**。若程序在分配后忘了回收，就会导致跟堆内存类似的泄漏问题。

## 内存中的buffer 和 cache

内存查看命令：free 和 top。buffer 和 cache 从 free 命令得到。因此，执行man free 后，可以得到如下说明：

* buffer：memory used by kernel buffers (buffers in /proc/meminfo)
* cache:   memory used by the page cache and slabs. (cached and SReclaimable in /proc/meminfo)

buffer 和 cache 数据来源均为 /proc/, 具体区别如下：

* Buffers 是**对原始磁盘块的临时存储**，也就是用来**缓存磁盘的数据**，通常不会特别大（20MB 左右）。这样，内核就可以把分散的**写**集中起来，统一优化磁盘的写入，将把多次小的写合并成单次大的写等。
* Cached 是**从磁盘读取文件的页缓存**，也就是用来**缓存从文件读取的数据**。下次访问这些数据时，可直接从内存中获取，不需再次访问缓慢的磁盘。
* SReclaimable 是 Slab 的一部分。Slab 包括两部分，其中的可回收部分，用 SReclaimable 记录；而不可回收部分，用 SUnreclaim 记录。

**proc文件系统**

/proc 是linux内核提供的特殊文件系统，是用户跟内核交互的接口。

* 用户可从/proc 中查询和修改内核运行状态和配置选项：cat /proc/xxxx
* /proc 也是很多性能工具数据来源，通过： man proc 搜索对应解析。

### 利用系统缓存优化代码运行效率

**根据实际案例观察**

* **Buffer：对磁盘数据的缓存，读写都会用上**

* **Cache: 对文件数据的缓存，读写都会用上**

Buffer和Cache设计目的是为了提升系统的I/O性能，因此，从读写角度可以：

* 写：代码在数据真正落盘前就返回做其他工作。
* 读：提高频繁访问数据的代码部分读取速度，降低频繁I/O对磁盘的压力。

**可行的思路**

* **缓存命中率**（直接通过请求缓存获取数据的次数占总请求次数的百分比）：缓存命中率越高，使用缓存带来的收益越高，代码性能越好。

  * **cachestat：整个操作系统缓存的读写命中情况。**
  * **cachetop：每个进程的缓存命中情况。**
  * 两者均为bcc软件包的一部分,因此需要先安装bcc

* **指定文件在内存中的缓存大小**：通过pcstat来查看文件在内存中的缓存大小及比例

* 如果为系统设置直接I/O的标志，就会绕过系统缓存，导致速度极慢。

  * strace：判断应用程序是否用了直接 I/O。

    命令：strace -p $(pgrep app)   查找示例app的进程号并输出结果

    【结果若包含：O_RDONLY-只读打开，O_DIRECT-直接读绕过缓存】

## 内存泄露-动态内存未释放引起

### 定位和处理

* 定位内存泄露：

  执行：vmstat 3 # 每隔3s输出一组数据

  * 若memory 列free 不停变化且为下降趋势 & buffer、cacahe 基本不变，则还需进一步使用工具来确认是否存在内存泄露的问题。
  * 专门检测内存泄露的工具：memleak【跟踪系统或指定进程的内存分配、释放请求、定期输出未释放内存和相应调用栈的汇总情况】
  * 通过memleak 的输出结果定位到未释放内存的代码后，进一步就是查看源码进行解决。【添加free(变量)释放内存】

* Memleak 安装配置及使用命令

  * bcc 软件包中的一个工具。

  * **执行：/usr/share/bcc/tools/memleak**

    eg： /usr/share/bcc/tools/memleak -a -p 进程pid 【-a 显示每个内存分配请求的大小及地址】

    **从输出结果可看出pid对应进程是否在不停分配内存且内存未回收，同时可以看到具体进程中占用内存未释放的函数。**

    ```
    $ docker cp app:/app /app
    $ /usr/share/bcc/tools/memleak -p $(pidof app) -a
    Attaching to pid 12512, Ctrl+C to quit.
    [03:00:41] Top 10 stacks with outstanding allocations:
        addr = 7f8f70863220 size = 8192
        addr = 7f8f70861210 size = 8192
        addr = 7f8f7085b1e0 size = 8192
        addr = 7f8f7085f200 size = 8192
        addr = 7f8f7085d1f0 size = 8192
        40960 bytes in 5 allocations from stack
          fibonacci+0x1f [app] #app进程中fibonacci 函数未释放
    ```

    代码新增free()修复后重新执行memleak不再显示具体的addr，证明内存已释放。

## swap

当内存泄露or运行大内存应用程序导致内存资源紧张时，系统可能采取两种方式：内存回收 or OOM杀死进程（杀死内存占用过大的进程）。

**内存回收**

* **缓存和缓冲区-文件页（File-backed Page）**：可回收内存。在内存管理中。大部分文件页可直接回收，需要时，再从磁盘重新读取。

* **脏页**：被应用程序修改过，且还没写入磁盘的数据。需先写入磁盘，再进行内存释放。写入方式：
  * 应用程序中，通过系统调用 fsync ，把脏页同步到磁盘中。
  * 系统，内核线程pdflush刷新脏页。
* **内存映射获取的文件映射页（文件页）**：它也可以被释放掉，下次再访问的时候，从文件重新读取。

* **应用程序动态分配的堆内存（匿名页Anonymous Page）**：可能还要被访问，无法直接回收。【若内存在分配后访问较少，也可以暂时先存放在磁盘里，释放给其他内存更需要的进程】

### 原理

* Swap 将不常访问的内存先写到磁盘中，然后释放这些内存，给其他更需要的进程使用。再次访问这些内存时，重新从磁盘读入内存就可以了。
* 实质：把一块磁盘空间或者一个本地文件，当成内存来使用。它包括换出和换入两个过程。
  * 换出:把进程暂时不用的内存数据存到磁盘并释放这些数据占用的内存。
  * 换入:在进程再次访问这些内存的时候，把它们从磁盘读到内存中来。

所以你看，Swap 其实是把系统的可用内存变大了。这样，即使服务器的内存不足，也可以运行大内存的应用程序。

还记得我最早学习 Linux 操作系统时，内存实在太贵了，一个普通学生根本就用不起大的内存，那会儿我就是开启了 Swap 来运行 Linux 桌面。当然，现在的内存便宜多了，服务器一般也会配置很大的内存，那是不是说 Swap 就没有用武之地了呢？

当然不是。事实上，内存再大，对应用程序来说，也有不够用的时候。

一个很典型的场景就是，即使内存不足时，有些应用程序也并不想被 OOM 杀死，而是希望能缓一段时间，等待人工介入，或者等系统自动释放其他进程的内存，再分配给它。

除此之外，我们常见的笔记本电脑的休眠和快速开机的功能，也基于 Swap 。休眠时，把系统的内存存入磁盘，这样等到再次开机时，只要从磁盘中加载内存就可以。这样就省去了很多应用程序的初始化过程，加快了开机速度。

话说回来，既然 Swap 是为了回收内存，那么 Linux 到底在什么时候需要回收内存呢？前面一直在说内存资源紧张，又该怎么来衡量内存是不是紧张呢？

一个最容易想到的场景就是，有新的大块内存分配请求，但是剩余内存不足。这个时候系统就需要回收一部分内存（比如前面提到的缓存），进而尽可能地满足新内存请求。这个过程通常被称为**直接内存回收**。

# 其他

## epoll 机制

 Epoll 是linux内核为了处理大批量文件描述而作了改进的poll，是linux下多路复用IO接口select/poll的增强版本，能够显著提高程序在高并发连接中只有少量活跃的情况下的系统CPU利用率。

* epoll的优点：
  * 支持一个进程打开大数目的socket描述。Select的一个进程打开的FD由FD_SETSIZE来设定，epoll没有这个限制，它所支持的FD上限是最大可打开文件数目，远大于2048.
  * IO效率不随FD数目增加而线性下降：由于epoll只会对“活跃”的socket进行操作，只有“活跃”的socket才会主动调用callback函数，其他idle状态的socket则不会。
  * mmap加速内核与用户空间的消息传递。Epoll 是通过内核与用户空间mmap同存一块内存而实现的。

## libev 机制

* 提供指定文件描述符合事件发生时调用回调函数的机制。Libev是一个事件循环器：向libev

* 注册事件，如socket可读事件，libev会对所注册的事件的源进行管理，并在事件发生时触发相应程序。

* gevent 方法spawn了一些jobs，然后通过gevent.joinall 将jobs加入到微线程的执行队列中等待其完成，设置超时时间为2s。执行后的结果通过检查gevent.greenlet.value 值来收集。
* Monket patching 的 python环境允许我们在运行时修改大部分对象，包括模块、类甚至函数。虽然这样做会产生“隐式副作用”，而且出现问题很难调试，但在需要修改python本身的基础行为时，monkey patching 就排上用场了。
  * 通过monkey.patch_socket()方法，urllib2模块可以在多微线程环境，达到与gevent共同工作的目的。
  * 事件循环：gevent和eventlet 类似，在一个greenlet中隐式循环。没有必须调用run() 或者dispatch() 的反应器（reactor），在wtisted中是有reactor的。当gevent的API函数想阻塞时，它获得Hub实例，并进行切换。
  * 提供的事件循环默认使用系统最快轮询机制，设置LIBEV_FLAGS环境变量可指定轮询机制。LIBEV_FLAGS =1 为select，2为poll，4为epoll，8为kqueue。

* Libev的API位于gevent,core下。注意libevAPI的回调在hub的greenlet上运行，因此使用同步greenlet的API，可以使用spawn() 和 event.set() 等异步API.

## C10k问题—操作系统处理高并发请求的问题

10 thousand clients problem

* problem raiser：Dan Kegel

* 技术层面定义c10k问题:设计不够良好的程序，其性能和连接数及机器的性能关系往往是非线性的。

  Eg：基于selector的程序在旧的服务器上能处理1000并发的吞吐量，但在2倍性能服务器上无法处理2000并发的吞吐量。因为策略不当时，大量操作的消耗和当前连接数n线性相关（单个任务资源消耗和当前连接数的关系是O（n））当服务程序对数以万计的socket进行IO处理，积累下来的资源消耗会相当可观。

* 问题本质: 操作系统的限制，传统同步阻塞IO模型处理方式都是requests per second，并发10k和100的关系区别在于CPU(创建的进程/线程多了，数据拷贝频繁-缓存IO,内核将数据拷贝到用户进程空间、阻塞；进程线程上下文切换消耗巨大，导致系统崩溃。

  解决问题的关键：减少CPU等核心计算资源消耗，从而榨干单台服务器的性能。

* 可能的解决方案: 每个进程、线程同时处理多个连接（IO多路复用）
  * 循环挨个处理连接，每个连接一个socket，当所有socket都有数据的时候，这种方法可行，但当某个socket的数据不ready的时候，整个应用阻塞等待。【DNS就是这个问题】
  * select 解决上面阻塞问题：在读取句柄之前，先查看确认状态，ready才进行处理。这样做的问题：小规模连接逐个检查句柄问题不大，大规模逐个检查状态就很慢。【selector 往往存在管理句柄上限。】
  * poll 解决select 的前两个问题，通过一个pollfd 数组向内核传递需要关注的事件消除句柄上限，同时使用不同字段分别标注事件和发生事件，来避免重复初始化。
  * epoll 解决逐个排查所有文件句柄状态效率不高的问题。假如调用返回的时候只给应用提供状态变化的文件句柄，就能提高排查效率。（当文件句柄数量达到10k的时候，epoll已经超过select 和 poll 两个数量级。）


------

