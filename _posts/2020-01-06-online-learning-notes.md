---
title: 'Online-learning-notes'
date: 2020-01-06
permalink: /posts/2020/01/Online-learning-notes/
tags:
  - cool posts
  - category1
  - category2
---

Online learning notes：coursera, etc.

[no ladder possible solution](https://blog.csdn.net/weixin_44491401/article/details/124091938)

# Machine Learning Yealing

## 基本点

* 优化策略的意义：正确优化策略带来的优化方向能对模型效果有直接提升，反之浪费测试时间。

* ML发展点：**数据量**越来越大、**计算资源**充足、加入神经网络基础后，随神经网络规模变大（**模型参数变多**），模型效果更好的概率更大。

* 设置开发集&测试集：避免自行采集的训练和测试集效果显著，但实际使用后效果变差（实际数据质量等方面达不到要求）。

  * 训练集: 训练算法
  * 开发集（实际情况数据，规模、样本数尽可能大）：调整参数
  * 测试集：评估算法性能。

  PS: **开发和测试集数据应该服从相同分布**，否则训练模型的提升对实际情况毫无意义。【开发集好，测试集差===算法过拟合，需要更多数据】

  PPS: **对于全新问题，通常通过开发集评估当前方法是否合适or需要被放弃**

* 单值评估指标进行优化（single-number evaluation metric）：precision、recall、F1等

* 满意度指标&优化指标：**优化指标是在满意度指标基础上形成的**

  * eg：既在乎准确度又在乎运行时间，则设定一个可接受参数限制（运行时间<100ms)再调整另一个-->【运行时间：满意度指标；准确度：优化指标】

* 开发集、测试集的指标修订

  新项目开展时，需尽快确定开发集和测试集，便于确定模型明确目标【Doing is better than always thinking】

## 基础误差分析

* 如果一开始不能设计构建出完美系统，那就从基础版本模型系统开始逐步迭代。

* 误差分析：检查被算法误分类开发集样本，找到误差原因进而确定改进方案优先级。

* 根据开发集评估想法的可行性需要将可能的提升率与时间成本比较看是否值得。

* 并行评估：将各种可行的方法创建成表格，同时观察误分类样本进行对比。

  eg：100个开发集的误分类样本

  | 图像 | 狗   | 大猫 | 模糊 |                    |
  | ---- | ---- | ---- | ---- | ------------------ |
  | 1    | yes  |      |      | 比特犬             |
  | 2    |      |      | yes  |                    |
  | 3    |      | yes  | yes  | 狮子在雨天拍的图片 |
  | 4    |      | yes  |      | 数目后的美洲豹     |
  | ...  |      |      |      |                    |
  | 占比 | 8%   | 43%  | 61%  |                    |

  以上表为例，处理大猫能够得到43%的改进，模糊类能够达到61%

* 开发集中，被误标注的数据值得被修正。

## 偏差与方差（非统计定义）






------

