---
title: 'Online-learning-notes'
date: 2020-01-06
permalink: /posts/2020/01/Online-learning-notes/
tags:
  - cool posts
  - category1
  - category2
---

Online learning notes：coursera, etc.

[no ladder possible solution](https://blog.csdn.net/weixin_44491401/article/details/124091938)

# Machine Learning Yealing

## 基本点

* 优化策略的意义：正确优化策略带来的优化方向能对模型效果有直接提升，反之浪费测试时间。

* ML发展点：**数据量**越来越大、**计算资源**充足、加入神经网络基础后，随神经网络规模变大（**模型参数变多**），模型效果更好的概率更大。

* 设置开发集&测试集：避免自行采集的训练和测试集效果显著，但实际使用后效果变差（实际数据质量等方面达不到要求）。

  * 训练集: 训练算法
  * 开发集（实际情况数据，规模、样本数尽可能大）：调整参数
  * 测试集：评估算法性能。

  PS: **开发和测试集数据应该服从相同分布**，否则训练模型的提升对实际情况毫无意义。【开发集好，测试集差===算法过拟合，需要更多数据】

  PPS: **对于全新问题，通常通过开发集评估当前方法是否合适or需要被放弃**

* 单值评估指标进行优化（single-number evaluation metric）：precision、recall、F1等

* 满意度指标&优化指标：**优化指标是在满意度指标基础上形成的**

  * eg：既在乎准确度又在乎运行时间，则设定一个可接受参数限制（运行时间<100ms)再调整另一个-->【运行时间：满意度指标；准确度：优化指标】

* 开发集、测试集的指标修订

  新项目开展时，需尽快确定开发集和测试集，便于确定模型明确目标【Doing is better than always thinking】

## 基础误差分析

* 如果一开始不能设计构建出完美系统，那就从基础版本模型系统开始逐步迭代。

* 误差分析：检查被算法误分类开发集样本，找到误差原因进而确定改进方案优先级。

* 根据开发集评估想法的可行性需要将可能的提升率与时间成本比较看是否值得。

* 并行评估：将各种可行的方法创建成表格，同时观察误分类样本进行对比。

  eg：100个开发集的误分类样本

  | 图像 | 狗   | 大猫 | 模糊 |                    |
  | ---- | ---- | ---- | ---- | ------------------ |
  | 1    | yes  |      |      | 比特犬             |
  | 2    |      |      | yes  |                    |
  | 3    |      | yes  | yes  | 狮子在雨天拍的图片 |
  | 4    |      | yes  |      | 数目后的美洲豹     |
  | ...  |      |      |      |                    |
  | 占比 | 8%   | 43%  | 61%  |                    |

  以上表为例，处理大猫能够得到43%的改进，模糊类能够达到61%

* 开发集中，被误标注的数据值得被修正。

## 偏差与方差（非统计定义）

* 偏差和方差的对比（两大误差来源，都是优化方向）
  * **偏差bias**：算法在训练集上的错误率。--【提高性能】
  * **方差variance**：算法在开发集比测试机表现差多少。 --【更好的泛化】
  * 偏差和方差将协助你决定是否该添加数据，并合理安排时间及策略去提升性能。当训练集的准确度无法达到目标的时候，此时并不能期望实际应用的准确度高于训练集，此时应有限考虑优化算法。拥有更多误差是无害的，但并不一定随时有帮助。
* 与最优错误率比较
  * **最优错误率=不可避免的误差**：在一个复杂任务中，即使人也无法完全识别的情况下，最终模型的效果一定低于最优错误率，否则存在overfitting的问题（当可避免的偏差已经优于最优错误率时，此时优化方向应该是提高泛化程度（方差）而不是减少偏差）。
  * 最优错误率（贝叶斯错误率）的获取：人类手工标注。
* 偏差与方差的处理
  * 较高可避免偏差：通过增大模型规模（添加层数、神经元数量来增大NN大小）。
  * 较高方差：增大训练集数量（覆盖类型更多的情况下训练）。
* 偏差与方差的tradeoff：尽可能不影响一方的情况下优化另一方。
* **减少可避免偏差的方法：**
  * 加大模型规模：一定程度上过拟合训练，减少偏差，若方差增加时，可通过**加入正则化能够抵消方差增加**。
  * 修改模型架构。
  * 减少或去正则化：避免偏差，增大方差。
  * 根据分类结果对输入特征进行增删。
  * 增加训练数据：优化方差，对偏差无效

* **方差减少方法**：

  * 增加训练数据
  * 加入正则化
  * 减小模型规模：降低方差但增大偏差。
  * 加入提前终止：降低方差但增大偏差。

* learning curve --- bias & variance

  学习曲线：随训练样本的数量增大，开发集合误差逐渐减小，靠近期望误差。【通过学习曲线能够避免花费几个月时间收集数据最后不管用的情况】

  <img src='/images/img/学习曲线.png'>

* training curve --- bias & variance

  训练误差曲线：评估添加数据带来的影响。（训练集增大，开发集和测试集误差减小，但训练集误差可能会上升）。

* 学习训练曲线解读

  <img src='/images/img/学习训练曲线1.png'>

  上图中error趋于平稳，不太可能通过增加数据量来达到预期性能。

  <img src='/images/img/学习训练曲线2.png'>

  加入训练误差后可以看出，增加数据后，training error 逐渐趋于稳定。

  <img src='/images/img/学习训练曲线3.png'>

  增加数据，缩小开发集的error

## 不同分布上进行训练和测试

* 通常：新数据和原数据整合后再统一进行处理达到“相同分布”的目的。
* 大数据时代，即使训练集和开发测试集不属于同一个分布，仍然希望用它来学习，因为可以提供大量的信息，但也存在新的问题。
* 如何决定是否使用不同分布的新数据：早期算法，直接合并两类数据会导致算法表现更差，但当模型足够大，反而可以在数据合并之后提升算法性能**（模型足够大为前提）**。
* 是否添加不一致的数据：不一致的参数中是否包含决定性的因素（eg：纽约房价&底特律房价，则两种样本之前没有参考价值）
* 数据&权重：假设20w互联网图片，5k用户图片，40：1的数据比例。这种情况可以通过权重将数据拉平（20w全部增加1/40的权重，确保图片重要性一致)
* 训练集泛化到开发集：训练集低误差难以泛化到不同分布的高误差数据集上，则尝试增加泛化数据样本，找到分部之间的差异来解决问题。
* 人工合成获取无法获取的数据：**合成过程需要考虑数据是否具有代表性。**

## 梯度检验：gradient checking

梯度下降训练过程，存在：cost function 下降，但最终prediction不理想的情况，此时适合采用gradient checking 来确保梯度下降算法正确，确认正确后，具体训练迭代时关闭检验部分。

```python

```




------

